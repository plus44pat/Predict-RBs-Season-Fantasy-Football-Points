{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f0e5d4e8",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0e5d4e8",
        "outputId": "841f0946-2d02-41b2-b99b-6803e13cd43c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nfl_data_py in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: pandas>1 in /usr/local/lib/python3.10/dist-packages (from nfl_data_py) (2.0.3)\n",
            "Requirement already satisfied: appdirs>1 in /usr/local/lib/python3.10/dist-packages (from nfl_data_py) (1.4.4)\n",
            "Requirement already satisfied: fastparquet>0.5 in /usr/local/lib/python3.10/dist-packages (from nfl_data_py) (2024.5.0)\n",
            "Requirement already satisfied: python-snappy>0.5 in /usr/local/lib/python3.10/dist-packages (from nfl_data_py) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fastparquet>0.5->nfl_data_py) (1.25.2)\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.10/dist-packages (from fastparquet>0.5->nfl_data_py) (2.8.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet>0.5->nfl_data_py) (2023.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet>0.5->nfl_data_py) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>1->nfl_data_py) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>1->nfl_data_py) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>1->nfl_data_py) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>1->nfl_data_py) (1.16.0)\n",
            "2010 done.\n",
            "2011 done.\n",
            "2012 done.\n",
            "2013 done.\n",
            "2014 done.\n",
            "2015 done.\n",
            "2016 done.\n",
            "2017 done.\n",
            "2018 done.\n",
            "2019 done.\n",
            "2020 done.\n",
            "2021 done.\n",
            "2022 done.\n",
            "2023 done.\n",
            "Downcasting floats.\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 672052 entries, 0 to 672051\n",
            "Columns: 390 entries, play_id to defense_coverage_type\n",
            "dtypes: float32(205), int32(7), int64(1), object(177)\n",
            "memory usage: 1.4+ GB\n",
            "None\n",
            "Downcasting floats.\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 75319 entries, 0 to 5652\n",
            "Data columns (total 53 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   player_id                    75319 non-null  object \n",
            " 1   player_name                  58784 non-null  object \n",
            " 2   player_display_name          75319 non-null  object \n",
            " 3   position                     75250 non-null  object \n",
            " 4   position_group               75250 non-null  object \n",
            " 5   headshot_url                 64487 non-null  object \n",
            " 6   recent_team                  75319 non-null  object \n",
            " 7   season                       75319 non-null  int32  \n",
            " 8   week                         75319 non-null  int32  \n",
            " 9   season_type                  75319 non-null  object \n",
            " 10  opponent_team                75319 non-null  object \n",
            " 11  completions                  75319 non-null  int32  \n",
            " 12  attempts                     75319 non-null  int32  \n",
            " 13  passing_yards                75319 non-null  float32\n",
            " 14  passing_tds                  75319 non-null  int32  \n",
            " 15  interceptions                75319 non-null  float32\n",
            " 16  sacks                        75319 non-null  float32\n",
            " 17  sack_yards                   75319 non-null  float32\n",
            " 18  sack_fumbles                 75319 non-null  int32  \n",
            " 19  sack_fumbles_lost            75319 non-null  int32  \n",
            " 20  passing_air_yards            75319 non-null  float32\n",
            " 21  passing_yards_after_catch    75319 non-null  float32\n",
            " 22  passing_first_downs          75319 non-null  float32\n",
            " 23  passing_epa                  9148 non-null   float32\n",
            " 24  passing_2pt_conversions      75319 non-null  int32  \n",
            " 25  pacr                         9050 non-null   float32\n",
            " 26  dakota                       8090 non-null   float32\n",
            " 27  carries                      75319 non-null  int32  \n",
            " 28  rushing_yards                75319 non-null  float32\n",
            " 29  rushing_tds                  75319 non-null  int32  \n",
            " 30  rushing_fumbles              75319 non-null  float32\n",
            " 31  rushing_fumbles_lost         75319 non-null  float32\n",
            " 32  rushing_first_downs          75319 non-null  float32\n",
            " 33  rushing_epa                  30732 non-null  float32\n",
            " 34  rushing_2pt_conversions      75319 non-null  int32  \n",
            " 35  receptions                   75319 non-null  int32  \n",
            " 36  targets                      75319 non-null  int32  \n",
            " 37  receiving_yards              75319 non-null  float32\n",
            " 38  receiving_tds                75319 non-null  int32  \n",
            " 39  receiving_fumbles            75319 non-null  float32\n",
            " 40  receiving_fumbles_lost       75319 non-null  float32\n",
            " 41  receiving_air_yards          75319 non-null  float32\n",
            " 42  receiving_yards_after_catch  75319 non-null  float32\n",
            " 43  receiving_first_downs        75319 non-null  float32\n",
            " 44  receiving_epa                60847 non-null  float32\n",
            " 45  receiving_2pt_conversions    75319 non-null  int32  \n",
            " 46  racr                         60345 non-null  float32\n",
            " 47  target_share                 60847 non-null  float32\n",
            " 48  air_yards_share              60847 non-null  float32\n",
            " 49  wopr                         60847 non-null  float32\n",
            " 50  special_teams_tds            75319 non-null  float32\n",
            " 51  fantasy_points               75319 non-null  float32\n",
            " 52  fantasy_points_ppr           75319 non-null  float32\n",
            "dtypes: float32(29), int32(15), object(9)\n",
            "memory usage: 18.4+ MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8424 entries, 0 to 8423\n",
            "Data columns (total 58 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   player_id                    8424 non-null   object \n",
            " 1   season                       8424 non-null   int32  \n",
            " 2   season_type                  8424 non-null   object \n",
            " 3   completions                  8424 non-null   int32  \n",
            " 4   attempts                     8424 non-null   int32  \n",
            " 5   passing_yards                8424 non-null   float64\n",
            " 6   passing_tds                  8424 non-null   int32  \n",
            " 7   interceptions                8424 non-null   float64\n",
            " 8   sacks                        8424 non-null   float64\n",
            " 9   sack_yards                   8424 non-null   float64\n",
            " 10  sack_fumbles                 8424 non-null   int32  \n",
            " 11  sack_fumbles_lost            8424 non-null   int32  \n",
            " 12  passing_air_yards            8424 non-null   float64\n",
            " 13  passing_yards_after_catch    8424 non-null   float64\n",
            " 14  passing_first_downs          8424 non-null   float64\n",
            " 15  passing_epa                  8424 non-null   float64\n",
            " 16  passing_2pt_conversions      8424 non-null   int32  \n",
            " 17  pacr                         8424 non-null   float64\n",
            " 18  dakota                       8424 non-null   float64\n",
            " 19  carries                      8424 non-null   int32  \n",
            " 20  rushing_yards                8424 non-null   float64\n",
            " 21  rushing_tds                  8424 non-null   int32  \n",
            " 22  rushing_fumbles              8424 non-null   float64\n",
            " 23  rushing_fumbles_lost         8424 non-null   float64\n",
            " 24  rushing_first_downs          8424 non-null   float64\n",
            " 25  rushing_epa                  8424 non-null   float64\n",
            " 26  rushing_2pt_conversions      8424 non-null   int32  \n",
            " 27  receptions                   8424 non-null   int32  \n",
            " 28  targets                      8424 non-null   int32  \n",
            " 29  receiving_yards              8424 non-null   float64\n",
            " 30  receiving_tds                8424 non-null   int32  \n",
            " 31  receiving_fumbles            8424 non-null   float64\n",
            " 32  receiving_fumbles_lost       8424 non-null   float64\n",
            " 33  receiving_air_yards          8424 non-null   float64\n",
            " 34  receiving_yards_after_catch  8424 non-null   float64\n",
            " 35  receiving_first_downs        8424 non-null   float64\n",
            " 36  receiving_epa                8424 non-null   float64\n",
            " 37  receiving_2pt_conversions    8424 non-null   int32  \n",
            " 38  racr                         8424 non-null   float64\n",
            " 39  target_share                 8424 non-null   float64\n",
            " 40  air_yards_share              8424 non-null   float64\n",
            " 41  wopr_x                       8424 non-null   float64\n",
            " 42  special_teams_tds            8424 non-null   float64\n",
            " 43  fantasy_points               8424 non-null   float64\n",
            " 44  fantasy_points_ppr           8424 non-null   float64\n",
            " 45  games                        8424 non-null   int64  \n",
            " 46  tgt_sh                       8424 non-null   float64\n",
            " 47  ay_sh                        8424 non-null   float64\n",
            " 48  yac_sh                       8424 non-null   float64\n",
            " 49  wopr_y                       8424 non-null   float64\n",
            " 50  ry_sh                        8424 non-null   float64\n",
            " 51  rtd_sh                       8130 non-null   float64\n",
            " 52  rfd_sh                       8424 non-null   float64\n",
            " 53  rtdfd_sh                     8424 non-null   float64\n",
            " 54  dom                          8130 non-null   float64\n",
            " 55  w8dom                        8130 non-null   float64\n",
            " 56  yptmpa                       8424 non-null   float64\n",
            " 57  ppr_sh                       8424 non-null   float64\n",
            "dtypes: float64(41), int32(14), int64(1), object(2)\n",
            "memory usage: 3.3+ MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 2269 entries, 3258 to 7995\n",
            "Data columns (total 18 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   season       2269 non-null   int32  \n",
            " 1   draft_year   1305 non-null   float64\n",
            " 2   draft_team   1305 non-null   object \n",
            " 3   draft_round  1305 non-null   float64\n",
            " 4   draft_ovr    1305 non-null   float64\n",
            " 5   pfr_id       1981 non-null   object \n",
            " 6   cfb_id       2118 non-null   object \n",
            " 7   player_name  2269 non-null   object \n",
            " 8   pos          2269 non-null   object \n",
            " 9   school       2269 non-null   object \n",
            " 10  ht           2246 non-null   object \n",
            " 11  wt           2250 non-null   float64\n",
            " 12  forty        1934 non-null   float64\n",
            " 13  bench        1366 non-null   float64\n",
            " 14  vertical     1769 non-null   float64\n",
            " 15  broad_jump   1729 non-null   float64\n",
            " 16  cone         1271 non-null   float64\n",
            " 17  shuttle      1321 non-null   float64\n",
            "dtypes: float64(10), int32(1), object(7)\n",
            "memory usage: 327.9+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 3579 entries, 8577 to 12155\n",
            "Data columns (total 36 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   season            3579 non-null   int32  \n",
            " 1   round             3579 non-null   int32  \n",
            " 2   pick              3579 non-null   int32  \n",
            " 3   team              3579 non-null   object \n",
            " 4   gsis_id           2360 non-null   object \n",
            " 5   pfr_player_id     3568 non-null   object \n",
            " 6   cfb_player_id     3208 non-null   object \n",
            " 7   pfr_player_name   3579 non-null   object \n",
            " 8   hof               3579 non-null   bool   \n",
            " 9   position          3579 non-null   object \n",
            " 10  category          3579 non-null   object \n",
            " 11  side              3579 non-null   object \n",
            " 12  college           3579 non-null   object \n",
            " 13  age               3562 non-null   float64\n",
            " 14  to                3302 non-null   float64\n",
            " 15  allpro            3579 non-null   int32  \n",
            " 16  probowls          3579 non-null   int32  \n",
            " 17  seasons_started   3579 non-null   int32  \n",
            " 18  w_av              3302 non-null   float64\n",
            " 19  car_av            0 non-null      object \n",
            " 20  dr_av             3106 non-null   float64\n",
            " 21  games             3302 non-null   float64\n",
            " 22  pass_completions  3302 non-null   float64\n",
            " 23  pass_attempts     3302 non-null   float64\n",
            " 24  pass_yards        3302 non-null   float64\n",
            " 25  pass_tds          3302 non-null   float64\n",
            " 26  pass_ints         3302 non-null   float64\n",
            " 27  rush_atts         3302 non-null   float64\n",
            " 28  rush_yards        3302 non-null   float64\n",
            " 29  rush_tds          3302 non-null   float64\n",
            " 30  receptions        3302 non-null   float64\n",
            " 31  rec_yards         3302 non-null   float64\n",
            " 32  rec_tds           3302 non-null   float64\n",
            " 33  def_solo_tackles  2353 non-null   float64\n",
            " 34  def_ints          721 non-null    float64\n",
            " 35  def_sacks         1020 non-null   float64\n",
            "dtypes: bool(1), float64(19), int32(6), object(10)\n",
            "memory usage: 926.2+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 78469 entries, 0 to 5598\n",
            "Data columns (total 16 columns):\n",
            " #   Column                     Non-Null Count  Dtype              \n",
            "---  ------                     --------------  -----              \n",
            " 0   season                     78469 non-null  float64            \n",
            " 1   game_type                  78469 non-null  object             \n",
            " 2   team                       78469 non-null  object             \n",
            " 3   week                       78469 non-null  float64            \n",
            " 4   gsis_id                    78469 non-null  object             \n",
            " 5   position                   78469 non-null  object             \n",
            " 6   full_name                  78469 non-null  object             \n",
            " 7   first_name                 78469 non-null  object             \n",
            " 8   last_name                  78469 non-null  object             \n",
            " 9   report_primary_injury      54895 non-null  object             \n",
            " 10  report_secondary_injury    3014 non-null   object             \n",
            " 11  report_status              54895 non-null  object             \n",
            " 12  practice_primary_injury    78290 non-null  object             \n",
            " 13  practice_secondary_injury  4443 non-null   object             \n",
            " 14  practice_status            78469 non-null  object             \n",
            " 15  date_modified              73603 non-null  datetime64[us, UTC]\n",
            "dtypes: datetime64[us, UTC](1), float64(2), object(13)\n",
            "memory usage: 10.2+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Here is me just exploring the data set I have and looking into what is available. As you can see here, there are a lot of\n",
        "data points to look through. I can explain what each data set is as we go along\n",
        "'''\n",
        "!pip install nfl_data_py\n",
        "\n",
        "\n",
        "import nfl_data_py as nfl\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the years you want to pull data for\n",
        "years = list(range(2010, 2024))  # This generates a list of years from 2010 to 2023\n",
        "positions = ['QB', 'RB', 'WR', 'TE', 'OL', 'DL', 'LB', 'DB', 'K', 'P']  # Example positions, adjust as needed\n",
        "\n",
        "'''\n",
        "This is play by play data. It is where I will get important team stats like who is the coach, how long did the team hold onto\n",
        "the ball\n",
        "'''\n",
        "pbp_data = nfl.import_pbp_data(years)\n",
        "df_pbp = pd.DataFrame(pbp_data)\n",
        "print(df_pbp.info())\n",
        "\n",
        "'''\n",
        "\n",
        "This is the base of my data where it is telling me the amount of fantasy points along with crucial details such as rushing\n",
        "yards, receiving yards, targets. These are all valuable data points to let you know how well a player is doing\n",
        "'''\n",
        "weekly_data = nfl.import_weekly_data(years)\n",
        "df_weekly = pd.DataFrame(weekly_data)\n",
        "print(df_weekly.info())\n",
        "\n",
        "# This is similar to the weekly_data but for a season\n",
        "seasonal_data = nfl.import_seasonal_data(years)\n",
        "df_seasonal = pd.DataFrame(seasonal_data)\n",
        "print(df_seasonal.info())\n",
        "\n",
        "'''\n",
        "Import combine data for the specified years and positions. Thought this could be helpful, especially for rookies. But turns\n",
        "out it has a lot of null values\n",
        "'''\n",
        "combine_data = nfl.import_combine_data(years, positions)\n",
        "df_combine = pd.DataFrame(combine_data)\n",
        "print(df_combine.info())\n",
        "'''\n",
        "I use this data especially for rookies. It can also tell me if you are a higher draft pick, then you may be a better talent\n",
        "'''\n",
        "# Import draft picks for the specified years\n",
        "draft_picks_data = nfl.import_draft_picks(years)\n",
        "df_draft_picks = pd.DataFrame(draft_picks_data)\n",
        "print(df_draft_picks.info())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Import injuries for the specified years. If someone is out, it is a good thing to know\n",
        "years = list(range(2009, 2024))\n",
        "injuries_data = nfl.import_injuries(years)\n",
        "df_injuries = pd.DataFrame(injuries_data)\n",
        "print(df_injuries.info())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "481c0c63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "481c0c63",
        "outputId": "36248be2-da64-404d-db19-ea087b6ffb1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-ed67920a8b2a>:21: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  yearly_roster = pd.read_csv(csv_data)\n",
            "<ipython-input-11-ed67920a8b2a>:21: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  yearly_roster = pd.read_csv(csv_data)\n",
            "<ipython-input-11-ed67920a8b2a>:21: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  yearly_roster = pd.read_csv(csv_data)\n",
            "<ipython-input-11-ed67920a8b2a>:21: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  yearly_roster = pd.read_csv(csv_data)\n",
            "<ipython-input-11-ed67920a8b2a>:21: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  yearly_roster = pd.read_csv(csv_data)\n",
            "<ipython-input-11-ed67920a8b2a>:21: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  yearly_roster = pd.read_csv(csv_data)\n",
            "<ipython-input-11-ed67920a8b2a>:21: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  yearly_roster = pd.read_csv(csv_data)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: ''",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ed67920a8b2a>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Ensure the directory exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Step 5: Save the combined DataFrame to a new CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
          ]
        }
      ],
      "source": [
        "#Weekly Rosters. Useful to understand how many games each person was active:\n",
        "import pandas as pd\n",
        "import requests\n",
        "from io import StringIO\n",
        "import os\n",
        "\n",
        "# Step 1: Define the base URL and years. I had to get another weekly roster because I realized this one had more information I needed\n",
        "base_url = \"https://github.com/nflverse/nflverse-data/releases/download/weekly_rosters/roster_weekly_{}.csv\"\n",
        "years = range(2002, 2024)\n",
        "\n",
        "# Step 2: Initialize an empty DataFrame to hold all rosters\n",
        "all_rosters = pd.DataFrame()\n",
        "\n",
        "# Step 3: Loop through each year, download the CSV, and concatenate to the main DataFrame\n",
        "for year in years:\n",
        "    url = base_url.format(year)\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        csv_data = StringIO(response.text)\n",
        "        yearly_roster = pd.read_csv(csv_data)\n",
        "        all_rosters = pd.concat([all_rosters, yearly_roster], ignore_index=True)\n",
        "    else:\n",
        "        print(f\"Failed to download roster for year {year}\")\n",
        "\n",
        "# Step 4: Define the output file path\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\combined_rosters_2002_2023.csv\"\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
        "\n",
        "# Step 5: Save the combined DataFrame to a new CSV file\n",
        "all_rosters.to_csv(output_file_path, index=False)\n",
        "\n",
        "'''\n",
        "Even though I was looking at Running backs, I wanted all Rosters because I wanted to understand the Running Backs Teammates.\n",
        "If the Running Back was surrounded by Pro Bowlers, then they should ideally be better. If the Running Back had Pro Bowl\n",
        "Offensive Lineman around him, he would be even better. Also, if the Defense had more pro bowlers, the Running back\n",
        "may be doing worse\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ae10d46",
      "metadata": {
        "id": "5ae10d46"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the output file path. This is the output file path from the previous script that holds the rosters week on week for all positions\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\combined_rosters_2002_2023.csv\"\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv(output_file_path)\n",
        "\n",
        "# Filter the DataFrame to include only rows where season is greater than or equal to 2010 and game_type is 'REG'\n",
        "df_filtered = df[(df['season'] >= 2010) & (df['game_type'] == 'REG')]\n",
        "\n",
        "'''\n",
        "For Rosters, I choose 2010 because I would eventually use a 11 year window from 2012-2023. For data from 2010, I sometimes needed\n",
        "it to see historically if they were injured.\n",
        "'''\n",
        "\n",
        "# Define the columns to keep\n",
        "columns_to_keep = [\n",
        "    'season', 'team', 'position', 'depth_chart_position', 'status', 'full_name',\n",
        "    'first_name', 'last_name', 'birth_date', 'height', 'weight', 'college',\n",
        "    'years_exp', 'week', 'game_type', 'status_description_abbr', 'entry_year',\n",
        "    'rookie_year', 'draft_number'\n",
        "]\n",
        "\n",
        "'''\n",
        "This table will give me an idea of when there rookie year is and when they were drafted. This will eventually tell me how many\n",
        "years they had in the league.  For Running backs, around years 3-5 you are better, so I wanted to see if that was the case.\n",
        "'''\n",
        "df_weekly_roster = df_filtered[columns_to_keep]\n",
        "'''\n",
        "I realized between some of the tables, the team names were different. Therefore, this is just me mapping all the teams to the\n",
        "correct initials\n",
        "'''\n",
        "\n",
        "\n",
        "# Define the team name mappings\n",
        "team_mappings = {\n",
        "    'PIT': 'PIT', 'PHI': 'PHI', 'SD': 'LAC', 'BLT': 'BAL', 'DEN': 'DEN', 'TB': 'TB',\n",
        "    'CLV': 'CLE', 'WAS': 'WAS', 'JAX': 'JAX', 'DAL': 'DAL', 'NYJ': 'NYJ', 'NO': 'NO',\n",
        "    'CHI': 'CHI', 'TEN': 'TEN', 'GB': 'GB', 'ARZ': 'ARI', 'NE': 'NE', 'MIN': 'MIN',\n",
        "    'ATL': 'ATL', 'DET': 'DET', 'MIA': 'MIA', 'SEA': 'SEA', 'CAR': 'CAR', 'CIN': 'CIN',\n",
        "    'IND': 'IND', 'BUF': 'BUF', 'SF': 'SF', 'HST': 'HOU', 'KC': 'KC', 'SL': 'LA',\n",
        "    'NYG': 'NYG', 'OAK': 'LV', 'ARI': 'ARI', 'HOU': 'HOU', 'BAL': 'BAL', 'CLE': 'CLE',\n",
        "    'LA': 'LA', 'LAC': 'LAC', 'LV': 'LV'\n",
        "}\n",
        "\n",
        "# Update the 'team' column using the replace method\n",
        "df_weekly_roster['team'] = df_weekly_roster['team'].replace(team_mappings)\n",
        "\n",
        "# LB is a very vague position and I wanted to understand if they played OLB or ILB or MLB. Therefore, wanted to change LB\n",
        "df_weekly_roster.loc[(df_weekly_roster['position'] == 'LB') & (df_weekly_roster['depth_chart_position'].notna()), 'position'] = df_weekly_roster['depth_chart_position']\n",
        "\n",
        "# Create a new DataFrame with counts of each position for each player, team, and season combination\n",
        "position_counts = df_weekly_roster.groupby(['full_name', 'team', 'season', 'position']).size().reset_index(name='count')\n",
        "\n",
        "# Find the most frequent position for each player, team, and season combination. This was helpful for filling out if position was blank or they were set to LB\n",
        "most_frequent_positions = position_counts.groupby(['full_name', 'team', 'season']).apply(lambda x: x.loc[x['count'].idxmax()]).reset_index(drop=True)\n",
        "\n",
        "# Define the output file path for processed data\n",
        "processed_output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\position_count.csv\"\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(os.path.dirname(processed_output_file_path), exist_ok=True)\n",
        "\n",
        "# Save the processed DataFrame to a new CSV file\n",
        "most_frequent_positions.to_csv(processed_output_file_path, index=False)\n",
        "\n",
        "# Merge the most frequent positions back to the main DataFrame\n",
        "df_weekly_roster = pd.merge(df_weekly_roster, most_frequent_positions, on=['full_name', 'team', 'season'], how='left', suffixes=('', '_most_frequent'))\n",
        "\n",
        "# Replace 'LB' position with the most frequent position for each player, team, and season combination\n",
        "df_weekly_roster.loc[df_weekly_roster['position'] == 'LB', 'position'] = df_weekly_roster['position_most_frequent']\n",
        "\n",
        "# Drop the temporary columns\n",
        "df_weekly_roster.drop(columns=['position_most_frequent', 'count'], inplace=True)\n",
        "\n",
        "# Define the position mappings for new columns. I will need Offensive Line and Defensive Line attributes to understand how well a Running Back will do\n",
        "position_mappings = {\n",
        "    'T': {'Defense': 'No', 'Defensive Line': 'No', 'Offensive Line': 'Yes', 'Offense': 'No'},\n",
        "    'K': {'Defense': 'No', 'Defensive Line': 'No', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'LS': {'Defense': 'No', 'Defensive Line': 'No', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'ILB': {'Defense': 'Yes', 'Defensive Line': 'No', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'CB': {'Defense': 'Yes', 'Defensive Line': 'No', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'QB': {'Defense': 'No', 'Defensive Line': 'No', 'Offensive Line': 'No', 'Offense': 'Yes'},\n",
        "    'P': {'Defense': 'No', 'Defensive Line': 'No', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'C': {'Defense': 'No', 'Defensive Line': 'No', 'Offensive Line': 'Yes', 'Offense': 'Yes'},\n",
        "    'OLB': {'Defense': 'Yes', 'Defensive Line': 'Conditional', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'FB': {'Defense': 'No', 'Defensive Line': 'No', 'Offensive Line': 'Yes', 'Offense': 'Yes'},\n",
        "    'TE': {'Defense': 'No', 'Defensive Line': 'No', 'Offensive Line': 'No', 'Offense': 'Yes'},\n",
        "    'DE': {'Defense': 'Yes', 'Defensive Line': 'Yes', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'FS': {'Defense': 'Yes', 'Defensive Line': 'No', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'DT': {'Defense': 'Yes', 'Defensive Line': 'Yes', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'WR': {'Defense': 'No', 'Defensive Line': 'No', 'Offensive Line': 'No', 'Offense': 'Yes'},\n",
        "    'G': {'Defense': 'No', 'Defensive Line': 'No', 'Offensive Line': 'Yes', 'Offense': 'Yes'},\n",
        "    'RB': {'Defense': 'No', 'Defensive Line': 'No', 'Offensive Line': 'No', 'Offense': 'Yes'},\n",
        "    'NT': {'Defense': 'Yes', 'Defensive Line': 'Yes', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'SS': {'Defense': 'Yes', 'Defensive Line': 'No', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'MLB': {'Defense': 'Yes', 'Defensive Line': 'No', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'DB': {'Defense': 'Yes', 'Defensive Line': 'No', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'LB': {'Defense': 'Yes', 'Defensive Line': 'No', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'PR': {'Defense': 'No', 'Defensive Line': 'No', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'KR': {'Defense': 'No', 'Defensive Line': 'No', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'S': {'Defense': 'Yes', 'Defensive Line': 'No', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'DL': {'Defense': 'Yes', 'Defensive Line': 'Yes', 'Offensive Line': 'No', 'Offense': 'No'},\n",
        "    'OL': {'Defense': 'No', 'Defensive Line': 'No', 'Offensive Line': 'Yes', 'Offense': 'Yes'}\n",
        "}\n",
        "\n",
        "# Create the initial new columns based on the position mappings\n",
        "df_weekly_roster['Defense'] = df_weekly_roster['position'].map(lambda x: position_mappings.get(x, {}).get('Defense', 'No'))\n",
        "df_weekly_roster['Defensive Line'] = df_weekly_roster['position'].map(lambda x: position_mappings.get(x, {}).get('Defensive Line', 'No'))\n",
        "df_weekly_roster['Offensive Line'] = df_weekly_roster['position'].map(lambda x: position_mappings.get(x, {}).get('Offensive Line', 'No'))\n",
        "df_weekly_roster['Offense'] = df_weekly_roster['position'].map(lambda x: position_mappings.get(x, {}).get('Offense', 'No'))\n",
        "\n",
        "\n",
        "# Adjust 'Defensive Line' for OLB based on the presence of NT in the same team and season. If you have a NT, it means the OLB is apart of the defensive line\n",
        "# Create a flag to indicate if NT is present in each team and season\n",
        "df_weekly_roster['NT_flag'] = df_weekly_roster.apply(lambda row: 1 if row['position'] == 'NT' or row['depth_chart_position'] == 'NT' else 0, axis=1)\n",
        "team_season_nt = df_weekly_roster.groupby(['team', 'season'])['NT_flag'].sum().reset_index()\n",
        "team_season_nt['NT_present'] = team_season_nt['NT_flag'] > 0\n",
        "team_season_nt.drop(columns='NT_flag', inplace=True)\n",
        "\n",
        "# Merge the NT presence information back to the main dataframe\n",
        "df_weekly_roster = pd.merge(df_weekly_roster, team_season_nt, on=['team', 'season'], how='left')\n",
        "\n",
        "# Update the 'Defensive Line' column for OLB based on the NT presence\n",
        "df_weekly_roster['Defensive Line'] = df_weekly_roster.apply(\n",
        "    lambda row: 'Yes' if row['position'] == 'OLB' and row['NT_present'] else row['Defensive Line'], axis=1\n",
        ")\n",
        "\n",
        "# Drop the temporary NT presence columns\n",
        "df_weekly_roster.drop(columns=['NT_flag', 'NT_present'], inplace=True)\n",
        "\n",
        "# Define the output file path for processed data\n",
        "processed_output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\weekly_roster.csv\"\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(os.path.dirname(processed_output_file_path), exist_ok=True)\n",
        "\n",
        "# Save the processed DataFrame to a new CSV file\n",
        "df_weekly_roster.to_csv(processed_output_file_path, index=False)\n",
        "\n",
        "\n",
        "# Display the first few rows of the filtered DataFrame\n",
        "print(df_weekly_roster.head())\n",
        "print(df_weekly_roster.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a69fc14f",
      "metadata": {
        "id": "a69fc14f"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "'''\n",
        "The Point of this section is to understand who is a pro bowler and how good your offense or defense is. Eventually, this\n",
        "actually becomes a valuable predictive tool for fantasy points\n",
        "'''\n",
        "# Define the file path. I had to use wikipedia to fill it out. Here is the file: https://docs.google.com/spreadsheets/d/1_w94P4EOn7lSpeEvwAQ8gZVQhS5qq22gdyPpBEpiUrY/edit#gid=0\n",
        "file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\Pro Bowl.csv\"\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "pro_bowl_df = pd.read_csv(file_path)\n",
        "\n",
        "# Define a function to process the \"Year(s) selected\" column. This is me pulling the year from the notes so I can get an accurate count of Pro Bowlers\n",
        "def process_years_selected(years_selected, notes):\n",
        "    # Convert NaN to empty string\n",
        "    years_selected = '' if pd.isnull(years_selected) else str(years_selected)\n",
        "    notes = '' if pd.isnull(notes) else str(notes)\n",
        "    if notes:\n",
        "        # Extract years mentioned in the notes\n",
        "        years_mentioned = re.findall(r'\\d{4}', notes)\n",
        "        # Remove mentioned years from \"Year(s) selected\"\n",
        "        for year in years_mentioned:\n",
        "            years_selected = years_selected.replace(year, '')\n",
        "    # Remove brackets and numbers within brackets\n",
        "    years_selected = re.sub(r'\\[\\d+\\]', '', years_selected)\n",
        "    # Remove any extra commas and spaces\n",
        "    years_selected = years_selected.replace(',', '').strip()\n",
        "    return years_selected\n",
        "\n",
        "# Apply the function to process the \"Year(s) selected\" column\n",
        "pro_bowl_df['Year(s) selected'] = pro_bowl_df.apply(lambda row: process_years_selected(row['Year(s) selected'], row['Notes']), axis=1)\n",
        "\n",
        "# Remove rows where \"Name\" is null\n",
        "pro_bowl_df = pro_bowl_df.dropna(subset=['Name'])\n",
        "\n",
        "# Reset the index\n",
        "pro_bowl_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Initialize an empty list to store the processed data\n",
        "processed_data_list = []\n",
        "\n",
        "# Iterate over each row in the pro_bowl_df DataFrame\n",
        "for index, row in pro_bowl_df.iterrows():\n",
        "    # Split the \"Year(s) selected\" column by comma and strip whitespace\n",
        "    years_selected = row['Year(s) selected'].split()\n",
        "\n",
        "    # Check if there are more than 4 characters in any year\n",
        "    if any(len(year) > 4 for year in years_selected):\n",
        "        for year in years_selected:\n",
        "            if len(year) > 4:\n",
        "                processed_data_list.append({'Name': row['Name'],\n",
        "                                            'Position': row['Position'],\n",
        "                                            'Year': year,\n",
        "                                            'Franchise Represented': row['Franchise Represented'],\n",
        "                                            'Is Greater than 4 Characters?': 'Yes'})\n",
        "                years_selected.remove(year)\n",
        "\n",
        "    # Append the remaining years\n",
        "    for year in years_selected:\n",
        "        processed_data_list.append({'Name': row['Name'],\n",
        "                                    'Position': row['Position'],\n",
        "                                    'Year': year,\n",
        "                                    'Franchise Represented': row['Franchise Represented'],\n",
        "                                    'Is Greater than 4 Characters?': 'No'})\n",
        "\n",
        "# Create a DataFrame from the list of dictionaries\n",
        "pro_bowl_data = pd.DataFrame(processed_data_list)\n",
        "\n",
        "# Define the output file path for processed data. This eventually becomes this: https://docs.google.com/spreadsheets/d/1yccPxuegFGjQ1UzSDkg5dKHmIbNqva-BYlLZ9EGRNck/edit#gid=0\n",
        "processed_output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\probowl.csv\"\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(os.path.dirname(processed_output_file_path), exist_ok=True)\n",
        "\n",
        "# Save the processed DataFrame to a new CSV file\n",
        "pro_bowl_data.to_csv(processed_output_file_path, index=False)\n",
        "#Duane Brown had an empty team so I filled it in myself\n",
        "def process_franchise_represented(row):\n",
        "    # Special case for Duane Brown\n",
        "    if row['Name'] == 'Duane Brown':\n",
        "        return 'Houston Texans'\n",
        "\n",
        "    # Convert NaN to empty string\n",
        "    franchise_represented = '' if pd.isnull(row['Franchise Represented']) else str(row['Franchise Represented'])\n",
        "    years_selected = row['Year']\n",
        "\n",
        "    # Check if years are present\n",
        "    if pd.notnull(years_selected):\n",
        "        # Extract years and corresponding franchises\n",
        "        matches = re.findall(r'([^()]+)\\s+\\((\\d{4})', franchise_represented)\n",
        "        if matches:\n",
        "            # Sort matches by year in descending order\n",
        "            matches.sort(key=lambda x: int(x[1]), reverse=True)\n",
        "            for franchise, year in matches:\n",
        "                if int(year) <= int(years_selected):\n",
        "                    return franchise.strip()\n",
        "\n",
        "    # Return original value if no match found\n",
        "    return franchise_represented.strip()\n",
        "\n",
        "# Apply the function to process the \"Franchise Represented\" column\n",
        "pro_bowl_data['Franchise Represented'] = pro_bowl_data.apply(process_franchise_represented, axis=1)\n",
        "\n",
        "# Define a dictionary to map full team names to initials. Again, ensuring team names are all aligned so I can use the data later\n",
        "team_initials = {\n",
        "    \"New England Patriots\": \"NE\",\n",
        "    \"Green Bay Packers\": \"GB\",\n",
        "    \"Tampa Bay Buccaneers\": \"TB\",\n",
        "    \"Cincinnati Bengals\": \"CIN\",\n",
        "    \"New Orleans Saints\": \"NO\",\n",
        "    \"Indianapolis Colts\": \"IND\",\n",
        "    \"Baltimore Ravens\": \"BAL\",\n",
        "    \"Atlanta Falcons\": \"ATL\",\n",
        "    \"Cleveland Browns\": \"CLE\",\n",
        "    \"Houston Texans\": \"HOU\",\n",
        "    \"Carolina Panthers\": \"CAR\",\n",
        "    \"Las Vegas Raiders\": \"LV\",\n",
        "    \"Arizona Cardinals\": \"ARI\",\n",
        "    \"Seattle Seahawks\": \"SEA\",\n",
        "    \"Pittsburgh Steelers\": \"PIT\",\n",
        "    \"New York Giants\": \"NYG\",\n",
        "    \"Jacksonville Jaguars\": \"JAX\",\n",
        "    \"Los Angeles Chargers\": \"LAC\",\n",
        "    \"Denver Broncos\": \"DEN\",\n",
        "    \"Tennessee Titans\": \"TEN\",\n",
        "    \"Miami Dolphins\": \"MIA\",\n",
        "    \"Detroit Lions\": \"DET\",\n",
        "    \"New York Jets\": \"NYJ\",\n",
        "    \"Philadelphia Eagles\": \"PHI\",\n",
        "    \"Dallas Cowboys\": \"DAL\",\n",
        "    \"Kansas City Chiefs\": \"KC\",\n",
        "    \"Chicago Bears\": \"CHI\",\n",
        "    \"San Francisco 49ers\": \"SF\",\n",
        "    \"Washington Football Team/Commanders\": \"WAS\",\n",
        "    \"Buffalo Bills\": \"BUF\",\n",
        "    \"Los Angeles Rams\": \"LA\",\n",
        "    \"Minnesota Vikings\": \"MIN\",\n",
        "    \"Washington Redskins\": \"WAS\",\n",
        "    \"Oakland Raiders\": 'LV',\n",
        "    \"San Diego Chargers\": \"LAC\",\n",
        "    \"Los Angeles/St. Louis Rams\": \"LA\",\n",
        "    \"Los Angeles Raiders\": 'LV',\n",
        "    \"Houston Oilers/Tennessee Oilers/Titans\": 'TEN',\n",
        "    \"Los Angeles/Oakland Raiders\": 'LV',\n",
        "    \"St. Louis Rams\": 'LA',\n",
        "    \"Los Angeles Rams\": 'LA',\n",
        "    'Washington Redskins': 'WAS'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "# Define a function to map full team names to initials\n",
        "def map_to_initials(franchise_represented):\n",
        "    return team_initials.get(franchise_represented, franchise_represented)\n",
        "\n",
        "# Apply the function to process the \"Franchise Represented\" column\n",
        "pro_bowl_data['Franchise Represented'] = pro_bowl_data['Franchise Represented'].apply(map_to_initials)\n",
        "\n",
        "# Define the output file path for processed data. As mentioned, eventually becomes this: https://docs.google.com/spreadsheets/d/1yccPxuegFGjQ1UzSDkg5dKHmIbNqva-BYlLZ9EGRNck/edit#gid=0\n",
        "processed_output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\probowl_processed.csv\"\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(os.path.dirname(processed_output_file_path), exist_ok=True)\n",
        "\n",
        "# Save the processed DataFrame to a new CSV file\n",
        "pro_bowl_data.to_csv(processed_output_file_path, index=False)\n",
        "\n",
        "print(pro_bowl_data.info())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "232dd92e",
      "metadata": {
        "id": "232dd92e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Select the required columns\n",
        "columns_to_keep = [\n",
        "    'away_score', 'home_score', 'home_coach', 'away_coach', 'roof', 'surface', 'temp', 'wind',\n",
        "    'start_time', 'posteam', 'game_seconds_remaining', 'season_type', 'week', 'season',\n",
        "    'home_team', 'away_team', 'play_type', 'yards_gained','game_stadium','game_date'\n",
        "]\n",
        "\n",
        "# Ensure the columns exist in the dataframe\n",
        "existing_columns = [col for col in columns_to_keep if col in df_pbp.columns]\n",
        "df_pbp_selected = df_pbp[existing_columns]\n",
        "\n",
        "print(df_pbp_selected.info())\n",
        "\n",
        "# Define custom aggregation functions\n",
        "def last_non_blank(series):\n",
        "    return series.dropna().iloc[-1] if not series.dropna().empty else None\n",
        "\n",
        "def first_non_blank(series):\n",
        "    return series.dropna().iloc[0] if not series.dropna().empty else None\n",
        "\n",
        "'''\n",
        "I used the non blank functions to easily get the information I wanted. I wanted here to understand situations and see if things\n",
        "like type of grass/turf mattered or did the time of the game matter in terms of performance\n",
        "'''\n",
        "grouped = df_pbp_selected.groupby(['week', 'season', 'home_team', 'away_team']).agg(\n",
        "    home_score=('home_score', last_non_blank),\n",
        "    away_score=('away_score', last_non_blank),\n",
        "    home_coach=('home_coach', first_non_blank),\n",
        "    away_coach=('away_coach', first_non_blank),\n",
        "    roof=('roof', first_non_blank),\n",
        "    surface=('surface', first_non_blank),\n",
        "    stadium=('game_stadium', first_non_blank),\n",
        "    temp=('temp', first_non_blank),\n",
        "    wind=('wind', first_non_blank),\n",
        "    start_time=('start_time', first_non_blank),\n",
        "    game_date=('game_date', first_non_blank)\n",
        ").reset_index()\n",
        "\n",
        "'''\n",
        "This is what I'll use to see how much time the team of the running back spend on offense. The reason I wanted to know this\n",
        "is because the idea here is if you spend more time on the field, you should be able to get more points\n",
        "'''\n",
        "def calculate_time_of_possession(df):\n",
        "    df = df.sort_values(by='game_seconds_remaining', ascending=False)\n",
        "    home_team = df['home_team'].iloc[0]\n",
        "    away_team = df['away_team'].iloc[0]\n",
        "    possession_times = []\n",
        "\n",
        "    current_team = None\n",
        "    start_time = None\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        if current_team is None:\n",
        "            current_team = row['posteam']\n",
        "            start_time = row['game_seconds_remaining']\n",
        "        elif row['posteam'] != current_team:\n",
        "            end_time = row['game_seconds_remaining']\n",
        "            possession_times.append((current_team, start_time - end_time))\n",
        "            current_team = row['posteam']\n",
        "            start_time = end_time\n",
        "\n",
        "    if current_team is not None and start_time is not None:\n",
        "        possession_times.append((current_team, start_time))\n",
        "\n",
        "    possession_summary = {home_team: 0, away_team: 0}\n",
        "    for team, time in possession_times:\n",
        "        if team in possession_summary:\n",
        "            possession_summary[team] += time\n",
        "        else:\n",
        "            possession_summary[team] = time\n",
        "\n",
        "    return possession_summary\n",
        "\n",
        "grouped['home_time_of_possession'] = grouped.apply(lambda row: calculate_time_of_possession(\n",
        "    df_pbp_selected[\n",
        "        (df_pbp_selected['week'] == row['week']) &\n",
        "        (df_pbp_selected['season'] == row['season']) &\n",
        "        (df_pbp_selected['home_team'] == row['home_team']) &\n",
        "        (df_pbp_selected['away_team'] == row['away_team'])\n",
        "    ]\n",
        ")[row['home_team']], axis=1)\n",
        "\n",
        "grouped['away_time_of_possession'] = grouped.apply(lambda row: calculate_time_of_possession(\n",
        "    df_pbp_selected[\n",
        "        (df_pbp_selected['week'] == row['week']) &\n",
        "        (df_pbp_selected['season'] == row['season']) &\n",
        "        (df_pbp_selected['home_team'] == row['home_team']) &\n",
        "        (df_pbp_selected['away_team'] == row['away_team'])\n",
        "    ]\n",
        ")[row['away_team']], axis=1)\n",
        "\n",
        "'''\n",
        "Calculate passing yards, rushing yards, and total yards if 'yards_gained' exists. I wanted to understand if team yards\n",
        "meant more success for an individual player. It also tells me how many plays are ran for running and throwing. The idea\n",
        "here is if more running plays are ran, then more likely for the player to get fantasy points. I am also collectings\n",
        "yards for both the home team and away team because if there is a team who is very stingy on defense and doesn't allow many\n",
        "yards, then it is more likely that a player who faces them, will not do well\n",
        "'''\n",
        "if 'yards_gained' in df_pbp_selected.columns:\n",
        "    def calculate_yards_and_plays(df, team):\n",
        "        passing_yards = df[(df['posteam'] == team) & (df['play_type'] == 'pass')]['yards_gained'].sum()\n",
        "        rushing_yards = df[(df['posteam'] == team) & (df['play_type'] == 'run')]['yards_gained'].sum()\n",
        "        passing_plays = df[(df['posteam'] == team) & (df['play_type'] == 'pass')].shape[0]\n",
        "        rushing_plays = df[(df['posteam'] == team) & (df['play_type'] == 'run')].shape[0]\n",
        "        return passing_yards, rushing_yards, passing_plays, rushing_plays\n",
        "\n",
        "    home_passing_yards_list = []\n",
        "    away_passing_yards_list = []\n",
        "    home_rushing_yards_list = []\n",
        "    away_rushing_yards_list = []\n",
        "    home_total_yards_list = []\n",
        "    away_total_yards_list = []\n",
        "    home_passing_plays_list = []\n",
        "    away_passing_plays_list = []\n",
        "    home_rushing_plays_list = []\n",
        "    away_rushing_plays_list = []\n",
        "\n",
        "    for i, row in grouped.iterrows():\n",
        "        week = row['week']\n",
        "        season = row['season']\n",
        "        home_team = row['home_team']\n",
        "        away_team = row['away_team']\n",
        "\n",
        "        game_df = df_pbp_selected[\n",
        "            (df_pbp_selected['week'] == week) &\n",
        "            (df_pbp_selected['season'] == season) &\n",
        "            (df_pbp_selected['home_team'] == home_team) &\n",
        "            (df_pbp_selected['away_team'] == away_team)\n",
        "        ]\n",
        "\n",
        "        home_passing_yards, home_rushing_yards, home_passing_plays, home_rushing_plays = calculate_yards_and_plays(game_df, home_team)\n",
        "        away_passing_yards, away_rushing_yards, away_passing_plays, away_rushing_plays = calculate_yards_and_plays(game_df, away_team)\n",
        "\n",
        "        home_passing_yards_list.append(home_passing_yards)\n",
        "        away_passing_yards_list.append(away_passing_yards)\n",
        "        home_rushing_yards_list.append(home_rushing_yards)\n",
        "        away_rushing_yards_list.append(away_rushing_yards)\n",
        "        home_total_yards_list.append(home_passing_yards + home_rushing_yards)\n",
        "        away_total_yards_list.append(away_passing_yards + away_rushing_yards)\n",
        "        home_passing_plays_list.append(home_passing_plays)\n",
        "        away_passing_plays_list.append(away_passing_plays)\n",
        "        home_rushing_plays_list.append(home_rushing_plays)\n",
        "        away_rushing_plays_list.append(away_rushing_plays)\n",
        "\n",
        "    grouped['home_passing_yards'] = home_passing_yards_list\n",
        "    grouped['away_passing_yards'] = away_passing_yards_list\n",
        "    grouped['home_rushing_yards'] = home_rushing_yards_list\n",
        "    grouped['away_rushing_yards'] = away_rushing_yards_list\n",
        "    grouped['home_total_yards'] = home_total_yards_list\n",
        "    grouped['away_total_yards'] = away_total_yards_list\n",
        "    grouped['home_passing_plays'] = home_passing_plays_list\n",
        "    grouped['away_passing_plays'] = away_passing_plays_list\n",
        "    grouped['home_rushing_plays'] = home_rushing_plays_list\n",
        "    grouped['away_rushing_plays'] = away_rushing_plays_list\n",
        "\n",
        "# Function to determine the winning team. This is me also eventually trying to understand if team success matters in regards to fantasy points\n",
        "def determine_winner(row):\n",
        "    if row['home_score'] > row['away_score']:\n",
        "        return row['home_team']\n",
        "    elif row['away_score'] > row['home_score']:\n",
        "        return row['away_team']\n",
        "    else:\n",
        "        return 'tie'\n",
        "\n",
        "# Apply the function to determine the winning team\n",
        "grouped['winning_team'] = grouped.apply(determine_winner, axis=1)\n",
        "\n",
        "# Calculate the total time of possession and average time of possession for each game\n",
        "grouped['total_time_of_possession'] = grouped['home_time_of_possession'] + grouped['away_time_of_possession']\n",
        "average_possession = grouped['total_time_of_possession'].mean()\n",
        "\n",
        "'''\n",
        "Fill in null values for home and away time of possession. I just got the average time of possession per game - the time\n",
        "of possession that was there.\n",
        "'''\n",
        "grouped['home_time_of_possession'] = grouped.apply(\n",
        "    lambda row: average_possession - row['away_time_of_possession'] if pd.isnull(row['home_time_of_possession']) and not pd.isnull(row['away_time_of_possession']) else row['home_time_of_possession'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "grouped['away_time_of_possession'] = grouped.apply(\n",
        "    lambda row: average_possession - row['home_time_of_possession'] if pd.isnull(row['away_time_of_possession']) and not pd.isnull(row['home_time_of_possession']) else row['away_time_of_possession'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# For whatever reason, these games were missing time of possession. So I went to ESPN and autofilled these instances\n",
        "conditions = [\n",
        "    (grouped['week'] == 9) & (grouped['season'] == 2023) & (grouped['home_team'] == 'KC') & (grouped['away_team'] == 'MIA'),\n",
        "    (grouped['week'] == 12) & (grouped['season'] == 2023) & (grouped['home_team'] == 'CIN') & (grouped['away_team'] == 'PIT'),\n",
        "    (grouped['week'] == 13) & (grouped['season'] == 2023) & (grouped['home_team'] == 'PIT') & (grouped['away_team'] == 'ARI')\n",
        "]\n",
        "\n",
        "# Values to fill in for corresponding conditions\n",
        "values = [\n",
        "    {'home_time_of_possession': 1776, 'away_time_of_possession': 1824},\n",
        "    {'home_time_of_possession': 1363, 'away_time_of_possession': 2237},\n",
        "    {'home_time_of_possession': 1843, 'away_time_of_possession': 1757}\n",
        "]\n",
        "\n",
        "# Filling in the missing values based on conditions\n",
        "for condition, value in zip(conditions, values):\n",
        "    grouped.loc[condition, ['home_time_of_possession', 'away_time_of_possession']] = value\n",
        "\n",
        "\n",
        "# Display the resulting DataFrame\n",
        "print(grouped.head())\n",
        "print(grouped.info())\n",
        "\n",
        "# I saved things to a csv just in case and to double check the data\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\game_data.csv\"\n",
        "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
        "grouped.to_csv(output_file_path, index=False)\n",
        "\n",
        "'''\n",
        "Based on the results of temp and wind, it made me realize I sadly could not use those fields. There were too many null values\n",
        "to account for. This would be good for the future because the idea would be if it was snowing or going to be a cold game,\n",
        "then the amount of fantasy points would probably not be as high\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27cf0c82",
      "metadata": {
        "id": "27cf0c82"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "'''\n",
        "Define the output file path. I added a line for how many pro bowls won in the last three years and if they won a pro bowl\n",
        "last year. Here is the file I use: https://docs.google.com/spreadsheets/d/1yccPxuegFGjQ1UzSDkg5dKHmIbNqva-BYlLZ9EGRNck/edit#gid=0.\n",
        "Data pulled from wikipedia: https://en.wikipedia.org/wiki/List_of_NFL_pro_bowlers\n",
        "'''\n",
        "\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\Pro Bowl Processed with Past Year + Past 3 Years Super Bowl Counts - Sheet1.csv\"\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "pro_bowl_data = pd.read_csv(output_file_path)\n",
        "\n",
        "# Rename columns in pro_bowl_data to match df_weekly_roster\n",
        "pro_bowl_data.rename(columns={'Franchise Represented': 'team','Year': 'season', 'Name': 'full_name'}, inplace=True)\n",
        "\n",
        "# Replace '</ref>' with an empty string in the 'season' column\n",
        "pro_bowl_data['season'] = pro_bowl_data['season'].astype('str').str.replace('</ref>', '', regex=False)\n",
        "\n",
        "# Convert the 'season' column to integers\n",
        "pro_bowl_data['season'] = pro_bowl_data['season'].astype(int)\n",
        "\n",
        "# Perform a left join on team, season, and full_name\n",
        "merged_df = df_weekly_roster.merge(pro_bowl_data, on=['team', 'season', 'full_name'], how='left', indicator=True)\n",
        "\n",
        "# Add a column to indicate if the player was in the Pro Bowl\n",
        "merged_df['in_pro_bowl'] = merged_df['_merge'] == 'both'\n",
        "\n",
        "# Drop the merge indicator column\n",
        "merged_df.drop(columns=['_merge'], inplace=True)\n",
        "\n",
        "\n",
        "# Define the output file path for the merged data\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\combined_rosters_with_pro_bowl_info.csv\"\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
        "\n",
        "# Save the merged DataFrame to a new CSV file\n",
        "merged_df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(merged_df.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "488f3795",
      "metadata": {
        "id": "488f3795"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# This is getting injury status. If they are playing injured, it may be good to understand if they play the same\n",
        "print(df_injuries.info())\n",
        "print(df_injuries.head())\n",
        "\n",
        "unique_teams = df_injuries['report_status'].unique()\n",
        "\n",
        "print(unique_teams)\n",
        "\n",
        "df_filtered = df_injuries[['position', 'full_name', 'first_name', 'last_name', 'report_status', 'team', 'week',\n",
        "                          'report_primary_injury']]\n",
        "\n",
        "df_injuries['inj_probable_status'] = np.where(df_injuries['report_status'] == 'Probable', 1, 0)\n",
        "df_injuries['inj_questionable_status'] = np.where(df_injuries['report_status'] == 'Questionable', 1, 0)\n",
        "df_injuries['inj_doubtful_status'] = np.where(df_injuries['report_status'] == 'Doubtful', 1, 0)\n",
        "df_injuries['inj_out_status'] = np.where(df_injuries['report_status'] == 'Out', 1, 0)\n",
        "\n",
        "# Merge df_injuries onto merged_df based on 'full_name', 'team', 'season', and 'week', dropping overlapping columns\n",
        "merged_df_injuries = merged_df.merge(df_injuries, on=['full_name', 'team', 'season', 'week'], how='left', suffixes=('', '_df_injuries'))\n",
        "\n",
        "# Fill NaN values in the injury columns with 0\n",
        "injury_columns = ['inj_probable_status', 'inj_questionable_status', 'inj_doubtful_status', 'inj_out_status']\n",
        "merged_df_injuries[injury_columns] = merged_df_injuries[injury_columns].fillna(0).astype(int)\n",
        "\n",
        "# Drop overlapping columns from merged_df_injuries\n",
        "overlapping_columns = [col for col in merged_df_injuries.columns if col.endswith('_df_injuries')]\n",
        "merged_df_injuries = merged_df_injuries.drop(columns=overlapping_columns)\n",
        "\n",
        "# Add a field denoting if the players are playing or not\n",
        "merged_df_injuries['playing'] = np.where(merged_df_injuries['inj_out_status'] == 1, 0, 1)\n",
        "\n",
        "print(merged_df_injuries.info())\n",
        "\n",
        "# Define the output file path for the merged data\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\combined_rosters_with_pro_bowl_info_and_injury_info.csv\"\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
        "\n",
        "# Save the merged DataFrame to a new CSV file\n",
        "merged_df_injuries.to_csv(output_file_path, index=False)\n",
        "\n",
        "\n",
        "# Merge df_draft_picks onto merged_df_injuries based on 'full_name' and 'rookie_year'\n",
        "merged_df_injuries_draft = merged_df_injuries.merge(df_draft_picks, left_on=['full_name', 'rookie_year'], right_on=['pfr_player_name', 'season'], how='left')\n",
        "\n",
        "# Drop the redundant 'player_name' and 'season' columns from df_draft_picks\n",
        "merged_df_injuries_draft.drop(columns=['pfr_player_name'], inplace=True)\n",
        "\n",
        "# Merge the fields with suffixes \"_x\" and \"_y\"\n",
        "for col in merged_df_injuries_draft.columns:\n",
        "    if col.endswith('_x') and col[:-2] + '_y' in merged_df_injuries_draft.columns:\n",
        "        merged_df_injuries_draft[col[:-2]] = merged_df_injuries_draft[col].combine_first(merged_df_injuries_draft[col[:-2] + '_y'])\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "# Drop the columns with suffixes \"_x\" and \"_y\"\n",
        "merged_df_injuries_draft = merged_df_injuries_draft.drop(columns=[col for col in merged_df_injuries_draft.columns if col.endswith(('_x', '_y'))])\n",
        "\n",
        "print(merged_df_injuries_draft.info())\n",
        "\n",
        "# Define the output file path for the merged data\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\combined_rosters_with_pro_bowl_injury_draft_info.csv\"\n",
        "\n",
        "# Save the merged DataFrame to a new CSV file\n",
        "merged_df_injuries_draft.to_csv(output_file_path, index=False)\n",
        "\n",
        "'''\n",
        "Here I am logging every injury status and understanding if they are playing based on the injurty status. I also\n",
        "do add the pro bowl fields. Past Year means was the player a pro bowler in the previous seasion. Past 3 Years means\n",
        "how many times were they in the Pro Bowl in the last 3 years. I did this because if someone had 3/3 pro bowls in last 3 years,\n",
        "that means they are probably a very very good player. Therefore, they should be weighted higher\n",
        "'''\n",
        "fields_to_keep = [\n",
        "    'status',\n",
        "    'full_name',\n",
        "    'first_name',\n",
        "    'last_name',\n",
        "    'birth_date',\n",
        "    'height',\n",
        "    'weight',\n",
        "    'years_exp',\n",
        "    'week',\n",
        "    'game_type',\n",
        "    'entry_year',\n",
        "    'rookie_year',\n",
        "    'draft_number',\n",
        "    'Defense',\n",
        "    'Defensive Line',\n",
        "    'Offensive Line',\n",
        "    'Offense',\n",
        "    'in_pro_bowl',\n",
        "    'Past Year',\n",
        "    'Past 3 Years',\n",
        "    'inj_probable_status',\n",
        "    'inj_questionable_status',\n",
        "    'inj_doubtful_status',\n",
        "    'inj_out_status',\n",
        "    'playing',\n",
        "    'round',\n",
        "    'season',\n",
        "    'team',\n",
        "    'position',\n",
        "    'college',\n",
        "    'pick'\n",
        "]\n",
        "\n",
        "# Drop the specified fields\n",
        "merged_df_injuries_draft = merged_df_injuries_draft[fields_to_keep]\n",
        "\n",
        "print(merged_df_injuries_draft.info())\n",
        "\n",
        "# Define the output file path for the merged data\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\combined_rosters_with_pro_bowl_injury_draft_info_trimmed.csv\"\n",
        "\n",
        "# Save the merged DataFrame to a new CSV file\n",
        "merged_df_injuries_draft.to_csv(output_file_path, index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "172bc641",
      "metadata": {
        "id": "172bc641"
      },
      "outputs": [],
      "source": [
        "#data cleaning for weekly roster information\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(merged_df_injuries_draft.info())\n",
        "\n",
        "# Concatenate 'first_name' and 'last_name' if 'full_name' is null\n",
        "merged_df_injuries_draft['full_name'] = merged_df_injuries_draft.apply(lambda row: row['first_name'] + ' ' + row['last_name'] if pd.isnull(row['full_name']) else row['full_name'], axis=1)\n",
        "\n",
        "# Define a function to fill missing values based on 'full_name' and 'position.' Just looking at previous rows to fill the null values\n",
        "def fill_missing_values(row):\n",
        "    if pd.isnull(row['birth_date']):\n",
        "        same_name = merged_df_injuries_draft[(merged_df_injuries_draft['full_name'] == row['full_name']) & (merged_df_injuries_draft['position'] == row['position'])]\n",
        "        if not same_name.empty:\n",
        "            row['birth_date'] = same_name['birth_date'].iloc[0]\n",
        "            row['weight'] = same_name['weight'].iloc[0]\n",
        "            row['height'] = same_name['height'].iloc[0]\n",
        "            row['years_exp'] = same_name['years_exp'].iloc[0]\n",
        "            row['entry_year'] = same_name['entry_year'].iloc[0]\n",
        "            row['rookie_year'] = same_name['rookie_year'].iloc[0]\n",
        "            row['draft_number'] = same_name['draft_number'].iloc[0]\n",
        "            row['college'] = same_name['college'].iloc[0]\n",
        "    return row\n",
        "\n",
        "# Fill missing values using the defined function\n",
        "merged_df_injuries_draft = merged_df_injuries_draft.apply(fill_missing_values, axis=1)\n",
        "\n",
        "# Fill 'draft_number' with 'pick' where 'draft_number' is null\n",
        "merged_df_injuries_draft['draft_number'] = merged_df_injuries_draft['draft_number'].fillna(merged_df_injuries_draft['pick'])\n",
        "\n",
        "# Drop the 'pick' column\n",
        "merged_df_injuries_draft.drop(columns=['pick'], inplace=True)\n",
        "\n",
        "# Fill remaining missing values with NaN (just to ensure consistency, if necessary)\n",
        "merged_df_injuries_draft.fillna(np.nan, inplace=True)\n",
        "\n",
        "# Fill 'draft_number' with 'pick' where 'draft_number' is null\n",
        "merged_df_injuries_draft['Past Year'] = merged_df_injuries_draft['Past Year'].fillna(0)\n",
        "merged_df_injuries_draft['Past 3 Years'] = merged_df_injuries_draft['Past 3 Years'].fillna(0)\n",
        "\n",
        "\n",
        "print(merged_df_injuries_draft.info())\n",
        "\n",
        "# Define the output file path for the merged data\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\combined_rosters_with_pro_bowl_injury_draft_info_cleaning.csv\"\n",
        "\n",
        "# Save the merged DataFrame to a new CSV file\n",
        "merged_df_injuries_draft.to_csv(output_file_path, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04c1c9eb",
      "metadata": {
        "id": "04c1c9eb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "'''\n",
        "This section is where there is a lot of cleaning. I am trying to accurately have the necessary values, particularly pro bowl data\n",
        "'''\n",
        "\n",
        "# Convert 'Yes'/'No' to boolean values\n",
        "merged_df_injuries_draft['in_pro_bowl'] = merged_df_injuries_draft['in_pro_bowl'].astype(bool)\n",
        "\n",
        "# Create boolean masks for each condition\n",
        "defense_mask = merged_df_injuries_draft['Defense'] == 'Yes'\n",
        "defensive_line_mask = merged_df_injuries_draft['Defensive Line'] == 'Yes'\n",
        "offensive_line_mask = merged_df_injuries_draft['Offensive Line'] == 'Yes'\n",
        "offense_mask = merged_df_injuries_draft['Offense'] == 'Yes'\n",
        "past_year_mask = merged_df_injuries_draft['Past Year'] == 1\n",
        "past_3_years_mask = merged_df_injuries_draft['Past 3 Years'] == 1\n",
        "playing_mask = merged_df_injuries_draft['playing'] == 1\n",
        "pro_bowl_mask = merged_df_injuries_draft['in_pro_bowl']\n",
        "\n",
        "# Grouping by week, season, and team\n",
        "grouped = merged_df_injuries_draft.groupby(['week', 'season', 'team'])\n",
        "\n",
        "'''\n",
        "Calculate counts using boolean indexing and np.sum. This is getting the Pro Bowl Counts for each position over a certain time\n",
        "period. I decided on previous 3 years and 1 year because for football players, 3 years is a long time because of how short\n",
        "there careers are (average NFL player is in the NFL for roughly 5 years).  And 1 year because it is recent and might be more\n",
        "telling because maybe they just burst onto the scene\n",
        "'''\n",
        "results = grouped.agg(\n",
        "    Defense_Pro_Bowl_Count=('Defense', lambda x: np.sum(defense_mask[x.index] & pro_bowl_mask[x.index] & playing_mask[x.index])),\n",
        "    Defensive_Line_Pro_Bowl_Count=('Defensive Line', lambda x: np.sum(defensive_line_mask[x.index] & pro_bowl_mask[x.index] & playing_mask[x.index])),\n",
        "    Offensive_Line_Pro_Bowl_Count=('Offensive Line', lambda x: np.sum(offensive_line_mask[x.index] & pro_bowl_mask[x.index] & playing_mask[x.index])),\n",
        "    Offense_Pro_Bowl_Count=('Offense', lambda x: np.sum(offense_mask[x.index] & pro_bowl_mask[x.index] & playing_mask[x.index])),\n",
        "    Defense_Past_Year_Sum=('Defense', lambda x: np.sum(defense_mask[x.index] & past_year_mask[x.index] & playing_mask[x.index])),\n",
        "    Defensive_Line_Past_Year_Sum=('Defensive Line', lambda x: np.sum(defensive_line_mask[x.index] & past_year_mask[x.index] & playing_mask[x.index])),\n",
        "    Offensive_Line_Past_Year_Sum=('Offensive Line', lambda x: np.sum(offensive_line_mask[x.index] & past_year_mask[x.index] & playing_mask[x.index])),\n",
        "    Offense_Past_Year_Sum=('Offense', lambda x: np.sum(offense_mask[x.index] & past_year_mask[x.index] & playing_mask[x.index])),\n",
        "    Defense_Past_3_Years_Sum=('Defense', lambda x: np.sum(defense_mask[x.index[-3:]] & playing_mask[x.index[-3:]])),\n",
        "    Defensive_Line_Past_3_Years_Sum=('Defensive Line', lambda x: np.sum(defensive_line_mask[x.index[-3:]] & playing_mask[x.index[-3:]])),\n",
        "    Offensive_Line_Past_3_Years_Sum=('Offensive Line', lambda x: np.sum(offensive_line_mask[x.index[-3:]] & playing_mask[x.index[-3:]])),\n",
        "    Offense_Past_3_Years_Sum=('Offense', lambda x: np.sum(offense_mask[x.index[-3:]] & playing_mask[x.index[-3:]]))\n",
        ")\n",
        "\n",
        "# Reset index\n",
        "results.reset_index(inplace=True)\n",
        "\n",
        "# Selecting desired columns\n",
        "desired_columns = ['week', 'season', 'team',\n",
        "                   'Defense_Pro_Bowl_Count', 'Defensive_Line_Pro_Bowl_Count',\n",
        "                   'Offensive_Line_Pro_Bowl_Count', 'Offense_Pro_Bowl_Count',\n",
        "                   'Defense_Past_Year_Sum', 'Defensive_Line_Past_Year_Sum',\n",
        "                   'Offensive_Line_Past_Year_Sum', 'Offense_Past_Year_Sum',\n",
        "                   'Defense_Past_3_Years_Sum', 'Defensive_Line_Past_3_Years_Sum',\n",
        "                   'Offensive_Line_Past_3_Years_Sum', 'Offense_Past_3_Years_Sum']\n",
        "\n",
        "# Create DataFrame with selected columns\n",
        "pro_bowl_team_info_df = results[desired_columns]\n",
        "\n",
        "# Display the DataFrame\n",
        "print(pro_bowl_team_info_df.info())\n",
        "\n",
        "# Define output file path\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\pro_bowl_info_per_team_per_week.csv\"\n",
        "\n",
        "# Write DataFrame to CSV\n",
        "pro_bowl_team_info_df.to_csv(output_file_path, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "958288c9",
      "metadata": {
        "id": "958288c9"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "In this section, I am joining the team data I got a while ago onto the stats I collected. Team stats may be important because\n",
        "if your team is doing better, then you should be doing better too\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Define the output file path\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\game_data.csv\"\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "weekly_game_stats_data_df = pd.read_csv(output_file_path)\n",
        "\n",
        "# List of columns to keep\n",
        "columns_to_keep = [\n",
        "    'player_id', 'player_name', 'player_display_name', 'position', 'position_group',\n",
        "    'recent_team', 'season', 'week', 'season_type', 'opponent_team', 'completions',\n",
        "    'attempts', 'passing_yards', 'passing_tds', 'interceptions', 'sacks',\n",
        "    'sack_yards', 'sack_fumbles', 'sack_fumbles_lost', 'passing_air_yards',\n",
        "    'passing_yards_after_catch', 'passing_first_downs', 'passing_epa',\n",
        "    'passing_2pt_conversions', 'carries', 'rushing_yards', 'rushing_tds',\n",
        "    'rushing_fumbles', 'rushing_fumbles_lost', 'rushing_first_downs', 'rushing_epa',\n",
        "    'rushing_2pt_conversions', 'receptions', 'targets', 'receiving_yards',\n",
        "    'receiving_tds', 'receiving_fumbles', 'receiving_fumbles_lost',\n",
        "    'receiving_air_yards', 'receiving_yards_after_catch', 'receiving_first_downs',\n",
        "    'receiving_epa', 'receiving_2pt_conversions', 'racr', 'target_share',\n",
        "    'air_yards_share', 'wopr', 'special_teams_tds', 'fantasy_points', 'fantasy_points_ppr'\n",
        "]\n",
        "\n",
        "# Filter the DataFrame to keep only the specified columns\n",
        "df_weekly_filtered = df_weekly[columns_to_keep]\n",
        "\n",
        "# Ensure consistent data types\n",
        "weekly_game_stats_data_df['week'] = weekly_game_stats_data_df['week'].astype(int)\n",
        "weekly_game_stats_data_df['season'] = weekly_game_stats_data_df['season'].astype(int)\n",
        "\n",
        "# Trim team names\n",
        "weekly_game_stats_data_df['home_team'] = weekly_game_stats_data_df['home_team'].str.strip()\n",
        "weekly_game_stats_data_df['away_team'] = weekly_game_stats_data_df['away_team'].str.strip()\n",
        "\n",
        "# Ensure consistent data types\n",
        "df_weekly_filtered['week'] = df_weekly_filtered['week'].astype(int)\n",
        "df_weekly_filtered['season'] = df_weekly_filtered['season'].astype(int)\n",
        "\n",
        "# Trim team names\n",
        "df_weekly_filtered['recent_team'] = df_weekly_filtered['recent_team'].str.strip()\n",
        "df_weekly_filtered['opponent_team'] = df_weekly_filtered['opponent_team'].str.strip()\n",
        "\n",
        "# Further filter the DataFrame to keep only rows where position is 'RB' and season is between 2010 and 2023.\n",
        "#This range is chosen because I will eventually make it 2013 and I want to be able to search 13 years back\n",
        "df_weekly_filtered = df_weekly_filtered[(df_weekly_filtered['position'] == 'RB') &\n",
        "                                        (df_weekly_filtered['season'] >= 2010) &\n",
        "                                        (df_weekly_filtered['season'] <= 2023)]\n",
        "\n",
        "'''\n",
        "In the stats table, there is no option for home_team or away_team, so this is me trying to figure out if recent_team,\n",
        "which is actually the team they played for, matches the home_team or away_team. Once I know that, Ill be able to get\n",
        "the offense stats for the Running Backs Team and the Defensive Stats of the Team the Running Back is against\n",
        "'''\n",
        "# Define join options\n",
        "join_options = ['recent_team', 'opponent_team']\n",
        "\n",
        "# Initialize merge tables\n",
        "merge_tables = []\n",
        "\n",
        "# Perform the merges and add them to merge_tables\n",
        "for join_option in join_options:\n",
        "    merge_result1 = df_weekly_filtered.merge(\n",
        "        weekly_game_stats_data_df,\n",
        "        left_on=['week', 'season', join_option],\n",
        "        right_on=['week', 'season', 'home_team'],\n",
        "        how='left',\n",
        "        suffixes=('', '_y')  # Add suffix to identify columns from the right DataFrame\n",
        "    )\n",
        "    merge_tables.append(merge_result1)\n",
        "\n",
        "    merge_result2 = df_weekly_filtered.merge(\n",
        "        weekly_game_stats_data_df,\n",
        "        left_on=['week', 'season', join_option],\n",
        "        right_on=['week', 'season', 'away_team'],\n",
        "        how='left',\n",
        "        suffixes=('', '_y')  # Add suffix to identify columns from the right DataFrame\n",
        "    )\n",
        "    merge_tables.append(merge_result2)\n",
        "\n",
        "# Define columns to copy from merge2 to merge1 if they are NaN in merge1\n",
        "columns_to_copy = [\n",
        "    'home_score', 'away_score', 'home_coach', 'away_coach', 'roof', 'surface',\n",
        "    'temp', 'wind', 'start_time', 'home_time_of_possession', 'away_time_of_possession',\n",
        "    'home_passing_yards', 'away_passing_yards', 'home_rushing_yards', 'away_rushing_yards',\n",
        "    'home_total_yards', 'away_total_yards', 'winning_team', 'total_time_of_possession'\n",
        "]\n",
        "\n",
        "# Initialize final merge tables\n",
        "final_merge_tables = []\n",
        "\n",
        "# Perform the final merge and fill null values. This is me going through all the possible options of matching\n",
        "for i in range(0, len(merge_tables), 2):\n",
        "    merge1 = merge_tables[i]\n",
        "    merge2 = merge_tables[i + 1]\n",
        "    merge3 = merge1.copy()\n",
        "    merge4 = merge1.copy()\n",
        "\n",
        "    merge1[columns_to_copy] = merge1[columns_to_copy].combine_first(merge2[columns_to_copy])\n",
        "    merge3[columns_to_copy] = merge3[columns_to_copy].combine_first(merge2[columns_to_copy])\n",
        "    merge4[columns_to_copy] = merge4[columns_to_copy].combine_first(merge3[columns_to_copy])\n",
        "\n",
        "    final_merge_tables.extend([merge1, merge2, merge3, merge4])\n",
        "\n",
        "    # Fill in missing values in merge1 with values from merge2\n",
        "merge1_filled = merge1.combine_first(merge2)\n",
        "\n",
        "# Fill in any remaining null values with values from merge3\n",
        "merge1_filled = merge1_filled.combine_first(merge3)\n",
        "\n",
        "# Fill in any remaining null values with values from merge4\n",
        "merge1_filled = merge1_filled.combine_first(merge4)\n",
        "\n",
        "# Set merge1_filled as the final DataFrame\n",
        "final_df = merge1_filled\n",
        "\n",
        "#For whatever reason, there data was missing, so this is me filling it in for those players\n",
        "specific_situations = [\n",
        "    ('Jerick McKinnon', 'KC', 2023, 9, 1776, 1824),\n",
        "    ('Raheem Mostert', 'MIA', 2023, 9, 1776, 1824),\n",
        "    ('James Conner', 'ARI', 2023, 13, 1843, 1757),\n",
        "    ('Joe Mixon', 'CIN', 2023, 12, 1691, 1909),\n",
        "    ('Jeffery Wilson', 'MIA', 2023, 9, 1776, 1824),\n",
        "    ('Salvon Ahmed', 'MIA', 2023, 9, 1776, 1824),\n",
        "    ('La\\'Mical Perine', 'KC', 2023, 9, 1776, 1824),\n",
        "    ('Najee Harris', 'PIT', 2023, 12, 1691, 1909),\n",
        "    ('Najee Harris', 'PIT', 2023, 13, 1843, 1757),\n",
        "    ('Michael Carter', 'ARI', 2023, 13, 1843, 1757),\n",
        "    ('Isiah Pacheco', 'KC', 2023, 9, 1776, 1824),\n",
        "    ('Jaylen Warren', 'PIT', 2023, 12, 1691, 1909),\n",
        "    ('Jaylen Warren', 'PIT', 2023, 13, 1843, 1757)\n",
        "]\n",
        "\n",
        "# Update the specific situations with missing time of possession values\n",
        "for situation in specific_situations:\n",
        "    player, team, season, week, home_time, away_time = situation\n",
        "    final_df.loc[(final_df['player_display_name'] == player) &\n",
        "                 (final_df['recent_team'] == team) &\n",
        "                 (final_df['season'] == season) &\n",
        "                 (final_df['week'] == week), ['home_time_of_possession', 'away_time_of_possession']] = home_time, away_time\n",
        "\n",
        "# Aggregate statistics based on recent team\n",
        "final_df['time_of_possession'] = final_df.apply(lambda row: row['home_time_of_possession']\n",
        "                                                 if row['recent_team'] == row['home_team']\n",
        "                                                 else row['away_time_of_possession'], axis=1)\n",
        "final_df['team_passing_yards'] = final_df.apply(lambda row: row['home_passing_yards']\n",
        "                                            if row['recent_team'] == row['home_team']\n",
        "                                            else row['away_passing_yards'], axis=1)\n",
        "final_df['team_rushing_yards'] = final_df.apply(lambda row: row['home_rushing_yards']\n",
        "                                            if row['recent_team'] == row['home_team']\n",
        "                                            else row['away_rushing_yards'], axis=1)\n",
        "final_df['team_total_yards'] = final_df.apply(lambda row: row['home_total_yards']\n",
        "                                          if row['recent_team'] == row['home_team']\n",
        "                                          else row['away_total_yards'], axis=1)\n",
        "final_df['team_passing_plays'] = final_df.apply(lambda row: row['home_passing_plays']\n",
        "                                            if row['recent_team'] == row['home_team']\n",
        "                                            else row['away_passing_plays'], axis=1)\n",
        "final_df['team_rushing_plays'] = final_df.apply(lambda row: row['home_rushing_plays']\n",
        "                                            if row['recent_team'] == row['home_team']\n",
        "                                            else row['away_rushing_plays'], axis=1)\n",
        "\n",
        "# Fill 'surface' column with previous non-null values based on the stadium name\n",
        "final_df['surface'] = final_df.groupby('stadium')['surface'].ffill().bfill()\n",
        "\n",
        "# Remove date from 'start_time' and keep only the time part\n",
        "final_df['start_time'] = final_df['start_time'].apply(lambda x: x.split(',')[1].strip() if ',' in x else x)\n",
        "#This is me figuring out if it is a home game or away game\n",
        "final_df['home_or_away'] = np.where(final_df['recent_team'] == final_df['home_team'], 'home', 'away')\n",
        "#This is me figuring out who there head coach was. I also wanted to see if head coach mattered for predicting\n",
        "final_df['head_coach'] = np.where(final_df['recent_team'] == final_df['home_team'], final_df['home_coach'], final_df['away_coach'])\n",
        "#This is me seeing how many points were scored. The idea here is the more points your team scores, the better your fantasy points\n",
        "final_df['team_score'] = np.where(final_df['recent_team'] == final_df['home_team'], final_df['home_score'], final_df['away_score'])\n",
        "\n",
        "# List of columns to keep with any necessary renaming\n",
        "columns_to_keep = {\n",
        "    'player_id': 'player_id',\n",
        "    'player_display_name': 'player_name',\n",
        "    'position': 'position',\n",
        "    'recent_team': 'team',\n",
        "    'season': 'season',\n",
        "    'week': 'week',\n",
        "    'season_type': 'season_type',\n",
        "    'opponent_team': 'opponent_team',\n",
        "    'completions': 'completions',\n",
        "    'attempts': 'passing_attempts',\n",
        "    'passing_yards': 'passing_yards',\n",
        "    'passing_tds': 'passing_tds',\n",
        "    'interceptions': 'interceptions',\n",
        "    'sacks': 'sacks',\n",
        "    'sack_yards': 'sack_yards',\n",
        "    'sack_fumbles': 'sack_fumbles',\n",
        "    'sack_fumbles_lost': 'sack_fumbles_lost',\n",
        "    'passing_air_yards': 'passing_air_yards',\n",
        "    'passing_yards_after_catch': 'passing_yards_after_catch',\n",
        "    'passing_first_downs': 'passing_first_downs',\n",
        "    'passing_2pt_conversions': 'passing_2pt_conversions',\n",
        "    'carries': 'rushing_carries',\n",
        "    'rushing_yards': 'rushing_yards',\n",
        "    'rushing_tds': 'rushing_tds',\n",
        "    'rushing_fumbles': 'rushing_fumbles',\n",
        "    'rushing_fumbles_lost': 'rushing_fumbles_lost',\n",
        "    'rushing_first_downs': 'rushing_first_downs',\n",
        "    'rushing_2pt_conversions': 'rushing_2pt_conversions',\n",
        "    'receptions': 'receptions',\n",
        "    'targets': 'targets',\n",
        "    'receiving_yards': 'receiving_yards',\n",
        "    'receiving_tds': 'receiving_tds',\n",
        "    'receiving_fumbles': 'receiving_fumbles',\n",
        "    'receiving_fumbles_lost': 'receiving_fumbles_lost',\n",
        "    'receiving_air_yards': 'receiving_air_yards',\n",
        "    'receiving_yards_after_catch': 'receiving_yards_after_catch',\n",
        "    'receiving_first_downs': 'receiving_first_downs',\n",
        "    'receiving_2pt_conversions': 'receiving_2pt_conversions',\n",
        "    'special_teams_tds': 'special_teams_tds',\n",
        "    'fantasy_points': 'fantasy_points',\n",
        "    'fantasy_points_ppr': 'fantasy_points_ppr',\n",
        "    'roof': 'roof',\n",
        "    'surface': 'surface',\n",
        "    'stadium': 'stadium',\n",
        "    'start_time': 'start_time',\n",
        "    'game_date': 'game_date',\n",
        "    'winning_team': 'winning_team',\n",
        "    'time_of_possession': 'time_of_possession',\n",
        "    'team_passing_yards': 'team_passing_yards',\n",
        "    'team_rushing_yards': 'team_rushing_yards',\n",
        "    'team_total_yards': 'team_total_yards',\n",
        "    'team_passing_plays': 'team_passing_plays',\n",
        "    'team_rushing_plays': 'team_rushing_plays',\n",
        "    'head_coach': 'head_coach',\n",
        "    'team_score': 'amount of points scored by the team'\n",
        "}\n",
        "\n",
        "# Filter the DataFrame to keep only the specified columns and rename them\n",
        "final_df = final_df[list(columns_to_keep.keys())].rename(columns=columns_to_keep)\n",
        "\n",
        "# Filter to keep only 'REG' season_type\n",
        "final_df = final_df[final_df['season_type'] == 'REG']\n",
        "\n",
        "\n",
        "\n",
        "# Define the output file path for the merged data\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\weekly_player_stats_with_game_stats.csv\"\n",
        "\n",
        "\n",
        "final_df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(final_df.info())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d6c52f3",
      "metadata": {
        "id": "1d6c52f3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\combined_rosters_with_pro_bowl_injury_draft_info_cleaning.csv\"\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "pro_bowl_info_with_basic_info = pd.read_csv(output_file_path)\n",
        "\n",
        "\n",
        "\n",
        "print(pro_bowl_info_with_basic_info.info())\n",
        "\n",
        "print(final_df.info())\n",
        "\n",
        "# Remove duplicates from pro_bowl_info_with_basic_info DataFrame\n",
        "pro_bowl_info_with_basic_info.drop_duplicates(subset=['full_name', 'team', 'position', 'season','week'], keep='first', inplace=True)\n",
        "\n",
        "# Cleaning up some names that are slightly different. So made sure they matched.\n",
        "def update_full_name(row):\n",
        "    if row['full_name'] == 'Danny Ware' and row['position'] == 'RB':\n",
        "        return 'D.J. Ware'\n",
        "    elif row['full_name'] == 'Chris Wells' and row['position'] == 'RB':\n",
        "        return 'Beanie Wells'\n",
        "    elif row['full_name'] == 'Jeff Wilson' and row['position'] == 'RB' and row['team'] == 'SF' and row['season'] == 2018:\n",
        "        return 'Jeffery Wilson'\n",
        "    elif row['full_name'] == 'David Williams' and row['position'] == 'RB' and row['team'] == 'JAX' and row['season'] == 2018:\n",
        "        return 'Dave Williams'\n",
        "    elif row['full_name'] == 'Jeff Wilson' and row['position'] == 'RB' and row['team'] == 'SF' and row['season'] == 2019:\n",
        "        return 'Jeffery Wilson'\n",
        "    elif row['full_name'] == 'Jeff Wilson' and row['position'] == 'RB' and row['team'] == 'SF' and row['season'] == 2020:\n",
        "        return 'Jeffery Wilson'\n",
        "    elif row['full_name'] in ['JaMycal Hasty', 'JaMycal Hasty'] and row['position'] == 'RB' and row['team'] == 'SF' and row['season'] == 2020:\n",
        "        return 'Jamycal Hasty'\n",
        "    elif row['full_name'] == 'Adrian Killins Jr.' and row['position'] == 'RB' and row['team'] == 'PHI' and row['season'] == 2020:\n",
        "        return 'Adrian Killins'\n",
        "    elif row['full_name'] == 'Carnell Williams' and row['position'] == 'RB':\n",
        "        return 'Cadillac Williams'\n",
        "    else:\n",
        "        return row['full_name']\n",
        "\n",
        "\n",
        "# Apply the function to update the 'full_name' column\n",
        "pro_bowl_info_with_basic_info['full_name'] = pro_bowl_info_with_basic_info.apply(update_full_name, axis=1)\n",
        "\n",
        "# Check the DataFrame\n",
        "print(pro_bowl_info_with_basic_info)\n",
        "\n",
        "# Perform the left join\n",
        "pro_bowl_info_and_stats_df = pd.merge(final_df, pro_bowl_info_with_basic_info,\n",
        "                     how='left',\n",
        "                     left_on=['team', 'season', 'week', 'player_name'],\n",
        "                     right_on=['team', 'season', 'week', 'full_name'])\n",
        "\n",
        "# We now have all columns from both dataframes in merged_df\n",
        "# You can handle any column conflicts or overlapping columns later as neede\n",
        "\n",
        "# merged_df now contains the merged data without duplicated columns\n",
        "\n",
        "# Define the output file path for the merged data\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\pro_bowl_info_and_stats_df_and_injuries_right_after_merge.csv\"\n",
        "\n",
        "\n",
        "\n",
        "# Additional Conditions\n",
        "# If entry_year, draft_number, round, college, and rookie_year are null, then find them in the same table with someone who has the exact same full_name.\n",
        "null_columns = ['entry_year', 'draft_number', 'round', 'college', 'rookie_year']\n",
        "pro_bowl_info_and_stats_df[null_columns] = pro_bowl_info_and_stats_df.groupby('player_name')[null_columns].transform(lambda x: x.fillna(method='ffill'))\n",
        "\n",
        "# Fill in the round and draft number for Ray Agnew\n",
        "pro_bowl_info_and_stats_df.loc[pro_bowl_info_and_stats_df['player_name'] == 'George Farmer', 'entry_year'] = 2015\n",
        "pro_bowl_info_and_stats_df.loc[pro_bowl_info_and_stats_df['player_name'] == 'George Farmer', 'rookie_year'] = 2015\n",
        "\n",
        "# Fill in the round and draft number for Kendall Gaskins.\n",
        "pro_bowl_info_and_stats_df.loc[pro_bowl_info_and_stats_df['player_name'] == 'Don Jackson', 'entry_year'] = 2016\n",
        "pro_bowl_info_and_stats_df.loc[pro_bowl_info_and_stats_df['player_name'] == 'Don Jackson', 'rookie_year'] = 2016\n",
        "\n",
        "\n",
        "\n",
        "# If years_exp is null then do season - rookie_year\n",
        "pro_bowl_info_and_stats_df['years_exp'] = pro_bowl_info_and_stats_df['season'] - pro_bowl_info_and_stats_df['rookie_year']\n",
        "\n",
        "\n",
        "#This data was missing. So had to fill it in. This data is all pulled from footballdb. I want to know college to see if it matters\n",
        "college_updates = {\n",
        "    'Willis McGahee': 'Miami (Fla.)',\n",
        "    'Mewelde Moore': 'Tulane',\n",
        "    'Michael Turner': 'Northern Illinois',\n",
        "    'Greg Jones': 'Florida State',\n",
        "    'Ryan Grant': 'Notre Dame',\n",
        "    'Ronnie Brown': 'Auburn',\n",
        "    'Cedric Benson': 'Texas',\n",
        "    'Brandon Jacobs': 'Auburn',\n",
        "    'Montell Owens': 'Maine',\n",
        "    'Maurice Jones-Drew': 'UCLA',\n",
        "    'Leon Washington': 'Florida State',\n",
        "    'D.J. Ware': 'Georgia',\n",
        "    'Brian Leonard': 'Rutgers',\n",
        "    'Brandon Jackson': 'Nebraska',\n",
        "    'Michael Bush': 'Louisville',\n",
        "    'Jackie Battle': 'Houston',\n",
        "    'BenJarvus Green-Ellis': 'Ole Miss',\n",
        "    'Kregg Lumpkin': 'Georgia',\n",
        "    'Felix Jones': 'Arkansas',\n",
        "    'Rashard Mendenhall': 'Illinois',\n",
        "    'Ray Rice': 'Rutgers',\n",
        "    'Kevin Smith': 'UCF',\n",
        "    'Jacob Hester': 'LSU',\n",
        "    'Tashard Choice': 'Georgia Tech',\n",
        "    'Jalen Parmele': 'Toledo',\n",
        "    'Peyton Hillis': 'Arkansas',\n",
        "    'Lance Ball': 'Maryland',\n",
        "    'Isaac Redman': 'Bowie State',\n",
        "    'Kahlil Bell': 'California',\n",
        "    'Curtis Brinkley': 'Syracuse',\n",
        "    'Arian Foster': 'Tennessee',\n",
        "    'Shonn Greene': 'Iowa',\n",
        "    'Bernard Scott': 'Abilene Christian',\n",
        "    'LaRod Stephens-Howling': 'Pittsburgh',\n",
        "    'Knowshon Moreno': 'Georgia',\n",
        "    'Donald Brown': 'UConn',\n",
        "    'Beanie Wells': 'Ohio State',\n",
        "    'Mike Goodson': 'Texas A&M',\n",
        "    'Andre Brown': 'NC State',\n",
        "    'Javon Ringer': 'Michigan State',\n",
        "    'Chris Ogbonnaya': 'Texas',\n",
        "    'Keiland Williams': 'LSU',\n",
        "    'Keith Toston': 'Oklahoma State',\n",
        "    'Alfonso Smith': 'Kentucky',\n",
        "    'Chris Gronkowski': 'Arizona',\n",
        "    'Robert Hughes': 'Notre Dame',\n",
        "    'Richard Murphy': 'LSU',\n",
        "    'Armando Allen': 'Notre Dame',\n",
        "    'Phillip Tanner': 'Middle Tennessee State',\n",
        "    'Armond Smith': 'Union',\n",
        "    'William Powell': 'Kansas State',\n",
        "    'Collin Mooney': 'Army',\n",
        "    'Jeremy Stewart': 'Stanford',\n",
        "    'Josh Vaughan': 'Richmond',\n",
        "    'Jeff Demps': 'Florida',\n",
        "    'Ronnie Wingo': 'Arkansas',\n",
        "    'Ray Graham': 'Pittsburgh',\n",
        "    'Dennis Johnson': 'Arkansas',\n",
        "    'Michael Hill': 'Missouri Western State',\n",
        "    'Jonas Gray': 'Notre Dame',\n",
        "    'Tauren Poole': 'Tennessee',\n",
        "    'Ray Agnew': 'Southern Illinois',\n",
        "    'Silas Redd': 'USC',\n",
        "    'Darrin Reaves': 'UAB',\n",
        "    'Kendall Gaskins': 'Richmond',\n",
        "    'Glenn Winston': 'Michigan State',\n",
        "    'George Farmer': 'USC',\n",
        "    'Don Jackson': 'Nevada',\n",
        "    'Kevin Faulk': 'LSU',\n",
        "    'Fred Taylor': 'Florida',\n",
        "    'Ricky Williams': 'Texas',\n",
        "    'Sammy Morris': 'Texas Tech',\n",
        "    'Thomas Jones': 'Virginia',\n",
        "    'Dominic Rhodes': 'Midwestern State',\n",
        "    'Correll Buckhalter': 'Nebraska',\n",
        "    'Moran Norris': 'Kansas',\n",
        "    'Michael Bennett': 'Wisconsin',\n",
        "    'LaDainian Tomlinson': 'TCU',\n",
        "    'Clinton Portis': 'Miami',\n",
        "    'Maurice Morris': 'Oregon',\n",
        "    'Ladell Betts': 'Iowa',\n",
        "    'Antwaan Randle El': 'Indiana',\n",
        "    'Brian Westbrook': 'Villanova',\n",
        "    'Chester Taylor': 'Toledo',\n",
        "    'Rock Cartwright': 'Kansas State',\n",
        "    'Earnest Graham': 'Florida',\n",
        "    'Larry Johnson': 'Penn State',\n",
        "    'Jason Wright': 'Northwestern',\n",
        "    'Derrick Ward': 'Fresno State',\n",
        "    'Julius Jones': 'Notre Dame',\n",
        "    'Cadillac Williams': 'Auburn',\n",
        "    'Marion Barber': 'Minnesota',\n",
        "    'Mike Bell': 'Arizona',\n",
        "    'Patrick Cobbs': 'North Texas',\n",
        "    'Laurence Maroney': 'Minnesota',\n",
        "    'Joseph Addai': 'LSU',\n",
        "    'Jerious Norwood': 'Mississippi State',\n",
        "    'Jerome Harrison': 'Washington State',\n",
        "    'Quinton Ganther': 'Utah',\n",
        "    'Eldra Buckley': 'Tennessee-Chattanooga',\n",
        "    'Lorenzo Booker': 'Florida State',\n",
        "    'Garrett Wolfe': 'Northern Illinois',\n",
        "    'Thomas Clayton': 'Kansas State',\n",
        "    'Korey Hall': 'Boise State',\n",
        "    'Kenneth Darby': 'Alabama',\n",
        "    'Albert Young': 'Iowa',\n",
        "    'Jehuu Caulcrick': 'Michigan State',\n",
        "    'Steve Slaton': 'West Virginia',\n",
        "    'Ryan Torain': 'Arizona State',\n",
        "    'Mike Hart': 'Michigan',\n",
        "    'Jerome Johnson': 'Oregon',\n",
        "    'Brock Bolen': 'Louisville',\n",
        "    'Devin Moore': 'Wyoming',\n",
        "    'Tyrell Sutton': 'Northwestern',\n",
        "    'Kareem Huggins': 'Hofstra',\n",
        "    'Gartrell Johnson': 'Colorado State',\n",
        "    'Aaron Brown': 'TCU',\n",
        "    'James Davis': 'Clemson',\n",
        "    'Dimitri Nance': 'Arizona State',\n",
        "    'Javarris James': 'Miami',\n",
        "    'Chauncey Washington': 'USC',\n",
        "    'Jeremiah Johnson': 'Oregon',\n",
        "    'Eddie Williams': 'Idaho',\n",
        "    'Manase Tonga': 'BYU',\n",
        "    'Quinn Porter': 'Stillman',\n",
        "    'John Clay': 'Wisconsin',\n",
        "    'Mossis Madu': 'Oklahoma',\n",
        "    'Brandon Saine': 'Ohio State'\n",
        "}\n",
        "\n",
        "# Update college information in the DataFrame only if the college is null\n",
        "pro_bowl_info_and_stats_df['college'] = pro_bowl_info_and_stats_df['college'].fillna(\n",
        "    pro_bowl_info_and_stats_df['full_name'].map(college_updates)\n",
        ")\n",
        "\n",
        "# Fill in the round and draft number for Ray Agnew\n",
        "pro_bowl_info_and_stats_df.loc[pro_bowl_info_and_stats_df['player_name'] == 'Ray Agnew', 'round'] = 7\n",
        "pro_bowl_info_and_stats_df.loc[pro_bowl_info_and_stats_df['player_name'] == 'Ray Agnew', 'draft_number'] = 248\n",
        "\n",
        "# Fill in the round and draft number for Kendall Gaskins\n",
        "pro_bowl_info_and_stats_df.loc[pro_bowl_info_and_stats_df['player_name'] == 'Kendall Gaskins', 'round'] = 6\n",
        "pro_bowl_info_and_stats_df.loc[pro_bowl_info_and_stats_df['player_name'] == 'Kendall Gaskins', 'draft_number'] = 213\n",
        "\n",
        "# Fill in round if draft_number is not null and round is null\n",
        "mask = (pro_bowl_info_and_stats_df['draft_number'].notnull()) & (pro_bowl_info_and_stats_df['round'].isnull())\n",
        "pro_bowl_info_and_stats_df.loc[mask, 'round'] = np.ceil(pro_bowl_info_and_stats_df.loc[mask, 'draft_number'] / 32).astype(int)\n",
        "\n",
        "# Fill in draft_number if null\n",
        "max_draft_number = pro_bowl_info_and_stats_df['draft_number'].max()\n",
        "pro_bowl_info_and_stats_df['draft_number'] = pro_bowl_info_and_stats_df['draft_number'].fillna(\n",
        "    max(max_draft_number + 1, 257 + 1)\n",
        ")\n",
        "\n",
        "# If round is still null, fill it out as 8\n",
        "pro_bowl_info_and_stats_df['round'] = pro_bowl_info_and_stats_df['round'].fillna(8)\n",
        "\n",
        "#Researched this part and want to find conferences because maybe if they come from a specific conference, they are better\n",
        "college_conference_mapping = {\n",
        "    'Miami': 'Atlantic Coast Conference (ACC)',\n",
        "    'Tulane': 'American Athletic Conference (AAC)',\n",
        "    'Oregon State': 'Pac-12 Conference',\n",
        "    'Northern Illinois': 'Mid-American Conference (MAC)',\n",
        "    'Florida State': 'Atlantic Coast Conference (ACC)',\n",
        "    'Michigan State': 'Big Ten Conference',\n",
        "    'Notre Dame': 'Independent',\n",
        "    'Auburn': 'Southeastern Conference (SEC)',\n",
        "    'Texas': 'Big 12 Conference',\n",
        "    'Kansas State': 'Big 12 Conference',\n",
        "    'Maine': 'Colonial Athletic Association (CAA)',\n",
        "    'Coe': 'American Rivers Conference (ARC)',\n",
        "    'USC': 'Pac-12 Conference',\n",
        "    'Memphis': 'American Athletic Conference (AAC)',\n",
        "    'UCLA': 'Pac-12 Conference',\n",
        "    'Georgia': 'Southeastern Conference (SEC)',\n",
        "    'Illinois': 'Big Ten Conference',\n",
        "    'Oklahoma': 'Big 12 Conference',\n",
        "    'California': 'Pac-12 Conference',\n",
        "    'Rutgers': 'Big Ten Conference',\n",
        "    'Nebraska': 'Big Ten Conference',\n",
        "    'Louisville': 'Atlantic Coast Conference (ACC)',\n",
        "    'Marshall': 'Conference USA (C-USA)',\n",
        "    'Houston': 'American Athletic Conference (AAC)',\n",
        "    'Ole Miss': 'Southeastern Conference (SEC)',\n",
        "    'Chadron State': 'Rocky Mountain Athletic Conference (RMAC)',\n",
        "    'Arkansas': 'Southeastern Conference (SEC)',\n",
        "    'Oregon': 'Pac-12 Conference',\n",
        "    'East Carolina': 'American Athletic Conference (AAC)',\n",
        "    'UCF': 'American Athletic Conference (AAC)',\n",
        "    'LSU': 'Southeastern Conference (SEC)',\n",
        "    'Georgia Tech': 'Atlantic Coast Conference (ACC)',\n",
        "    'Toledo': 'Mid-American Conference (MAC)',\n",
        "    'Maryland': 'Big Ten Conference',\n",
        "    'Bowie State': 'Central Intercollegiate Athletic Association (CIAA)',\n",
        "    'Syracuse': 'Atlantic Coast Conference (ACC)',\n",
        "    'Tennessee': 'Southeastern Conference (SEC)',\n",
        "    'Iowa': 'Big Ten Conference',\n",
        "    'Virginia': 'Atlantic Coast Conference (ACC)',\n",
        "    'Abilene Christian': 'Western Athletic Conference (WAC)',\n",
        "    'Pittsburgh': 'Atlantic Coast Conference (ACC)',\n",
        "    'UConn': 'Independent',\n",
        "    'Ohio State': 'Big Ten Conference',\n",
        "    'Texas A&M': 'Southeastern Conference (SEC)',\n",
        "    'NC State': 'Atlantic Coast Conference (ACC)',\n",
        "    'Liberty': 'Independent',\n",
        "    'Wayne State (Mich.)': 'Great Lakes Intercollegiate Athletic Conference (GLIAC)',\n",
        "    'Oklahoma State': 'Big 12 Conference',\n",
        "    'Kentucky': 'Southeastern Conference (SEC)',\n",
        "    'Arizona': 'Pac-12 Conference',\n",
        "    'Tiffin University': 'Great Midwest Athletic Conference (G-MAC)',\n",
        "    'Mississippi State': 'Southeastern Conference (SEC)',\n",
        "    'Southern Illinois': 'Missouri Valley Football Conference (MVFC)',\n",
        "    'Buffalo': 'Mid-American Conference (MAC)',\n",
        "    'Clemson': 'Atlantic Coast Conference (ACC)',\n",
        "    'Fresno State': 'Mountain West Conference (MWC)',\n",
        "    'Stanford': 'Pac-12 Conference',\n",
        "    'Alabama': 'Southeastern Conference (SEC)',\n",
        "    'Virginia Tech': 'Atlantic Coast Conference (ACC)',\n",
        "    'Kansas St.': 'Big 12 Conference',\n",
        "    'Hawaii': 'Mountain West Conference (MWC)',\n",
        "    'Eastern Washington': 'Big Sky Conference',\n",
        "    'North Carolina': 'Atlantic Coast Conference (ACC)',\n",
        "    'Connecticut': 'Big East Conference',\n",
        "    'Penn State': 'Big Ten Conference',\n",
        "    'Texas Tech': 'Big 12 Conference',\n",
        "    'Utah': 'Pac-12 Conference',\n",
        "    'Troy': 'Sun Belt Conference',\n",
        "    'Middle Tennessee State': 'Conference USA (C-USA)',\n",
        "    'Union': 'Mid-South Conference (NAIA)',\n",
        "    'West Virginia': 'Big 12 Conference',\n",
        "    'Army': 'Independent',\n",
        "    'North Texas': 'Conference USA (C-USA)',\n",
        "    'Florida': 'Southeastern Conference (SEC)',\n",
        "    'Florida Atlantic': 'Conference USA (C-USA)',\n",
        "    'Appalachian State': 'Sun Belt Conference',\n",
        "    'Mississippi': 'Southeastern Conference (SEC)',\n",
        "    'Temple': 'American Athletic Conference (AAC)',\n",
        "    'Utah State': 'Mountain West Conference (MWC)',\n",
        "    'William & Mary': 'Colonial Athletic Association (CAA)',\n",
        "    'Boise State': 'Mountain West Conference (MWC)',\n",
        "    'Cincinnati': 'American Athletic Conference (AAC)',\n",
        "    'San Diego State': 'Mountain West Conference (MWC)',\n",
        "    'Richmond': 'Colonial Athletic Association (CAA)',\n",
        "    'Texas-El Paso': 'Conference USA (C-USA)',\n",
        "    'Western Kentucky': 'Conference USA (C-USA)',\n",
        "    'Washington': 'Pac-12 Conference',\n",
        "    'Massachusetts': 'Independent',\n",
        "    'Missouri Western State': 'Mid-America Intercollegiate Athletics Association (MIAA)',\n",
        "    'West Texas A&M': 'Lone Star Conference (LSC)',\n",
        "    'Miami (Fla.)': 'Atlantic Coast Conference (ACC)',\n",
        "    'Louisiana State': 'Southeastern Conference (SEC)',\n",
        "    'Wisconsin': 'Big Ten Conference',\n",
        "    'Vanderbilt': 'Southeastern Conference (SEC)',\n",
        "    'Michigan': 'Big Ten Conference',\n",
        "    'Central Florida': 'American Athletic Conference (AAC)',\n",
        "    'Alabama State': 'Southwestern Athletic Conference (SWAC)',\n",
        "    'Duke': 'Atlantic Coast Conference (ACC)',\n",
        "    'Central Michigan': 'Mid-American Conference (MAC)',\n",
        "    'Tulsa': 'American Athletic Conference (AAC)',\n",
        "    'Arizona State': 'Pac-12 Conference',\n",
        "    'Boston College': 'Atlantic Coast Conference (ACC)',\n",
        "    'Coastal Carolina': 'Sun Belt Conference',\n",
        "    'UAB': 'Conference USA (C-USA)',\n",
        "    'Towson': 'Colonial Athletic Association (CAA)',\n",
        "    'Georgia Southern': 'Sun Belt Conference',\n",
        "    'Kent State': 'Mid-American Conference (MAC)',\n",
        "    'Wake Forest': 'Atlantic Coast Conference (ACC)',\n",
        "    'No College': 'No College',\n",
        "    'Yale': 'Ivy League',\n",
        "    'Southern California': 'Pac-12 Conference',\n",
        "    'South Dakota': 'Missouri Valley Football Conference (MVFC)',\n",
        "    'Purdue': 'Big Ten Conference',\n",
        "    'North Dakota State': 'Missouri Valley Football Conference (MVFC)',\n",
        "    'Louisiana-Lafayette': 'Sun Belt Conference',\n",
        "    'Missouri': 'Southeastern Conference (SEC)',\n",
        "    'Indiana': 'Big Ten Conference',\n",
        "    'South Carolina': 'Southeastern Conference (SEC)',\n",
        "    'Minnesota': 'Big Ten Conference',\n",
        "    'Northern Iowa': 'Missouri Valley Football Conference (MVFC)',\n",
        "    'Montana': 'Big Sky Conference',\n",
        "    'Montana': 'Big Sky Conference',\n",
        "'Colorado State': 'Mountain West Conference (MWC)',\n",
        "'Azusa Pacific': 'Great Northwest Athletic Conference (GNAC)',\n",
        "'Eastern Michigan': 'Mid-American Conference (MAC)',\n",
        "'San Jose State': 'Mountain West Conference (MWC)',\n",
        "'Louisiana Tech': 'Conference USA (C-USA)',\n",
        "'Arkansas State': 'Sun Belt Conference',\n",
        "'Nevada': 'Mountain West Conference (MWC)',\n",
        "'Southern Mississippi': 'Conference USA (C-USA)',\n",
        "'Jacksonville State': 'Ohio Valley Conference (OVC)',\n",
        "'Idaho': 'Big Sky Conference',\n",
        "'North Carolina A&T': 'Mid-Eastern Athletic Conference (MEAC)',\n",
        "'Wyoming': 'Mountain West Conference (MWC)',\n",
        "'North Carolina State': 'Atlantic Coast Conference (ACC)',\n",
        "'Western State, Colo.': 'Rocky Mountain Athletic Conference (RMAC)',\n",
        "'Brigham Young': 'Independent',\n",
        "'South Florida': 'American Athletic Conference (AAC)',\n",
        "'West Georgia': 'Gulf South Conference (GSC)',\n",
        "'Colorado': 'Pac-12 Conference',\n",
        "'Virginia State': 'Central Intercollegiate Athletic Association (CIAA)',\n",
        "'Alcorn State': 'Southwestern Athletic Conference (SWAC)',\n",
        "'Northwestern': 'Big Ten Conference',\n",
        "'Western Carolina': 'Southern Conference (SoCon)',\n",
        "'Fordham': 'Patriot League',\n",
        "'Penn State': 'Big Ten Conference',\n",
        "'Slippery Rock': 'Pennsylvania State Athletic Conference (PSAC)',\n",
        "'Iowa State': 'Big 12 Conference',\n",
        "'Rice': 'Conference USA (C-USA)',\n",
        "'Texas A&M': 'Southeastern Conference (SEC)',\n",
        "'Kutztown': 'Pennsylvania State Athletic Conference (PSAC)',\n",
        "'Baylor': 'Big 12 Conference',\n",
        "'Illinois State': 'Missouri Valley Football Conference (MVFC)',\n",
        "'Western Michigan': 'Mid-American Conference (MAC)',\n",
        "'Navy': 'American Athletic Conference (AAC)',\n",
        "'New Mexico State': 'Independent',\n",
        "'Louisiana-Monroe': 'Sun Belt Conference',\n",
        "'Saginaw Valley State': 'Great Lakes Intercollegiate Athletic Conference (GLIAC)',\n",
        "'Tiffin': 'Great Midwest Athletic Conference (G-MAC)',\n",
        "'Alabama-Birmingham': 'Conference USA (C-USA)',\n",
        "'Ball State': 'Mid-American Conference (MAC)',\n",
        "'Sacred Heart': 'Northeast Conference (NEC)',\n",
        "'South Dakota State': 'Missouri Valley Football Conference (MVFC)',\n",
        "'Texas Christian': 'Big 12 Conference',\n",
        "'Youngstown State': 'Missouri Valley Football Conference (MVFC)',\n",
        "'Fort Valley State': 'Southern Intercollegiate Athletic Conference (SIAC)',\n",
        "'Northern Colorado': 'Big Sky Conference',\n",
        "    'Michigan St.': 'Big Ten Conference',\n",
        "    'Penn St.': 'Big Ten Conference',\n",
        "    'Ohio St.': 'Big Ten Conference',\n",
        "    'Arizona St.': 'Pac-12 Conference',\n",
        "    'Kent St.': 'Mid-American Conference (MAC)',\n",
        "    'Florida St.': 'Atlantic Coast Conference (ACC)',\n",
        "    'North Carolina A&amp;T': 'Mid-Eastern Athletic Conference (MEAC)',\n",
        "    'Texas A&amp;M': 'Southeastern Conference (SEC)',\n",
        "    'Midwestern State': 'Lone Star Conference (Division II)',\n",
        "    'Kansas': 'Big 12 Conference',\n",
        "    'TCU': 'Big 12 Conference',\n",
        "    'Villanova': 'Colonial Athletic Association (CAA) (FCS)',\n",
        "    'Washington State': 'Pac-12 Conference',\n",
        "    'Tennessee-Chattanooga': 'Southern Conference (SoCon) (FCS)',\n",
        "    'Hofstra': 'Conference USA (C-USA)',\n",
        "    'BYU': 'Big 12 Conference',\n",
        "    'Stillman': 'Southern Intercollegiate Athletic Conference (SIAC)'\n",
        "}\n",
        "\n",
        "# Add College Conference field\n",
        "pro_bowl_info_and_stats_df['College Conference'] = pro_bowl_info_and_stats_df['college'].map(college_conference_mapping)\n",
        "\n",
        "fields_to_drop = ['Defense', 'Defensive Line', 'Offensive Line', 'Offense']\n",
        "pro_bowl_info_and_stats_df.drop(fields_to_drop, axis=1, inplace=True)\n",
        "\n",
        "# Remove lines for 'Greg Jones' in season 2012 if position_y is 'MLB'. Also just removing duplicate lines\n",
        "pro_bowl_info_and_stats_df = pro_bowl_info_and_stats_df[~((pro_bowl_info_and_stats_df['player_name'] == 'Greg Jones') &\n",
        "                                                          (pro_bowl_info_and_stats_df['season'] == 2012) &\n",
        "                                                          (pro_bowl_info_and_stats_df['position_y'] == 'MLB'))]\n",
        "\n",
        "# Remove lines for Michael Carter in seasons 2021, 2022, and 2023 if position_y is 'DB'\n",
        "pro_bowl_info_and_stats_df = pro_bowl_info_and_stats_df[~((pro_bowl_info_and_stats_df['player_name'] == 'Michael Carter') &\n",
        "                                                          (pro_bowl_info_and_stats_df['season'].isin([2021, 2022, 2023])) &\n",
        "                                                          (pro_bowl_info_and_stats_df['position_y'] == 'DB'))]\n",
        "\n",
        "# Remove the position_y column\n",
        "pro_bowl_info_and_stats_df.drop(columns=['position_y'], inplace=True)\n",
        "\n",
        "# Rename position_x to position\n",
        "pro_bowl_info_and_stats_df.rename(columns={'position_x': 'position'}, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# Display the merged DataFrame\n",
        "print(pro_bowl_info_and_stats_df.info())\n",
        "\n",
        "# Define the output file path for the merged data\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\pro_bowl_info_and_stats_df_and_injuries.csv\"\n",
        "\n",
        "# Write the merged DataFrame to a CSV file\n",
        "pro_bowl_info_and_stats_df.to_csv(output_file_path, index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ac17044",
      "metadata": {
        "id": "1ac17044"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Here I am setting the base table I want. This is the per week data I use to predict how well a running back would do\n",
        "'''\n",
        "import pandas as pd\n",
        "\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\pro_bowl_info_per_team_per_week.csv\"\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "pro_bowl_team_info = pd.read_csv(output_file_path)\n",
        "\n",
        "# Joining pro_bowl_team_info based on season, week, and team\n",
        "merged_df = pd.merge(pro_bowl_info_and_stats_df, pro_bowl_team_info[['season', 'week', 'team',\n",
        "                    'Offensive_Line_Pro_Bowl_Count', 'Offensive_Line_Past_Year_Sum',\n",
        "                    'Offensive_Line_Past_3_Years_Sum', 'Offense_Pro_Bowl_Count',\n",
        "                    'Offense_Past_Year_Sum', 'Offense_Past_3_Years_Sum']],\n",
        "                    on=['season', 'week', 'team'], how='left')\n",
        "\n",
        "# Joining pro_bowl_team_info based on season, week, and opponent_team, and renaming the 'team' column to avoid duplicate columns\n",
        "week_on_week_data = pd.merge(merged_df, pro_bowl_team_info[['season', 'week', 'team',\n",
        "                    'Defense_Pro_Bowl_Count', 'Defense_Past_Year_Sum',\n",
        "                    'Defense_Past_3_Years_Sum', 'Defensive_Line_Pro_Bowl_Count',\n",
        "                    'Defensive_Line_Past_Year_Sum', 'Defensive_Line_Past_3_Years_Sum']],\n",
        "                    left_on=['season', 'week', 'opponent_team'], right_on=['season', 'week', 'team'], how='left')\n",
        "\n",
        "# Dropping duplicate columns if any\n",
        "week_on_week_data = week_on_week_data.loc[:,~week_on_week_data.columns.duplicated()]\n",
        "\n",
        "# Drop team_y column\n",
        "week_on_week_data.drop('team_y', axis=1, inplace=True)\n",
        "\n",
        "# Rename team_x to team\n",
        "week_on_week_data.rename(columns={'team_x': 'team'}, inplace=True)\n",
        "\n",
        "# Convert the column to integer type\n",
        "week_on_week_data['amount of points scored by the team'] = week_on_week_data['amount of points scored by the team'].astype(int)\n",
        "\n",
        "# Define the output file path for the merged data\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\week_on_week_data.csv\"\n",
        "\n",
        "# Write the merged DataFrame to a CSV file\n",
        "week_on_week_data.to_csv(output_file_path, index=False)\n",
        "\n",
        "\n",
        "# Displaying the resulting DataFrame\n",
        "print(week_on_week_data.info())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8bfd967",
      "metadata": {
        "id": "a8bfd967"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This is me corraling the data for the current season. So most stats are for the current season. This will help me\n",
        "find data from previous seasons\n",
        "'''\n",
        "# Step 1: Filter for season_type == 'REG'\n",
        "df = week_on_week_data[week_on_week_data['season_type'] == 'REG']\n",
        "\n",
        "print(df.info())\n",
        "\n",
        "# Rename the columns in the dataframe\n",
        "df.rename(columns={'Past Year': 'In_Pro_Bowl_Last_Year', 'Past 3 Years': 'Amount of Pro Bowls in Last 3 Years'}, inplace=True)\n",
        "\n",
        "# Step 2: Convert game_date and birth_date to datetime\n",
        "df['game_date'] = pd.to_datetime(df['game_date'])\n",
        "df['birth_date'] = pd.to_datetime(df['birth_date'])\n",
        "\n",
        "# Step 3: Calculate age as the difference in years between game_date and birth_date\n",
        "df['age'] = (df['game_date'] - df['birth_date']).dt.days // 365\n",
        "\n",
        "# Create the game_weekday column\n",
        "df['game_weekday'] = df['game_date'].dt.day_name()\n",
        "\n",
        "# Step 6: Add a new column to check if the player's team won\n",
        "df['win'] = df['team'] == df['winning_team']\n",
        "\n",
        "df['total_yards'] = df['rushing_yards'] + df['receiving_yards']\n",
        "\n",
        "    # Check if completions are over 7\n",
        "df['completions_over_7'] = np.where(df['completions'] >= 7, 1, 0)\n",
        "\n",
        "# Check if rushing carries are over 20\n",
        "df['rushing_carries_over_20'] = np.where(df['rushing_carries'] >= 20, 1, 0)\n",
        "\n",
        "# Check if rushing carries constitute over 70% of team rushing plays\n",
        "df['rushing_carries_70_percent'] = np.where((df['rushing_carries'] / df['team_rushing_plays']) > 0.7, 1, 0)\n",
        "\n",
        "# Check if rushing yards are over 100\n",
        "df['rushing_yards_over_100'] = np.where(df['rushing_yards'] >= 100, 1, 0)\n",
        "\n",
        "# Check if total yards are over 100\n",
        "df['total_yards_over_100'] = np.where(df['total_yards'] >= 100, 1, 0)\n",
        "\n",
        "# Check if rushing touchdowns are over 2\n",
        "df['rushing_tds_over_2'] = np.where(df['rushing_tds'] >= 2, 1, 0)\n",
        "\n",
        "# Check if receiving touchdowns are multiple\n",
        "df['receiving_tds_multiple'] = np.where(df['receiving_tds'] >= 2, 1, 0)\n",
        "\n",
        "# Check if receiving yards are over 100\n",
        "df['receiving_yards_over_100'] = np.where(df['receiving_yards'] >= 100, 1, 0)\n",
        "\n",
        "# Check if fantasy points are over 10\n",
        "df['fantasy_points_over_10'] = np.where(df['fantasy_points'] >= 10, 1, 0)\n",
        "\n",
        "# Check if fantasy points are over 10\n",
        "df['roof_outdoors'] = np.where(df['roof'] == 'outdoors', 1, 0)\n",
        "\n",
        "df['roof_dome'] = np.where(df['roof'] == 'dome',1,0)\n",
        "\n",
        "df['roof_open'] = np.where(df['roof'] == 'open',1,0)\n",
        "\n",
        "df['roof_closed'] = np.where(df['roof'] == 'closed',1,0)\n",
        "\n",
        "df['grass_field'] = np.where(df['surface'] == 'grass', 1, 0) + np.where(df['surface'] == 'grass ', 1, 0)\n",
        "\n",
        "df['astroturf_field'] =  np.where(df['surface'] == 'a_turf', 1, 0) + np.where(df['surface'] == 'astroturf', 1, 0) + np.where(df['surface'] == 'astroplay', 1, 0)\n",
        "\n",
        "df['other_turf_field'] =  np.where(df['surface'] == 'matrixturf', 1, 0) + np.where(df['surface'] == 'sportturf', 1, 0) + np.where(df['surface'] == 'fieldturf', 1, 0)\n",
        "\n",
        "df['fumbles'] = df['rushing_fumbles'] + df['receiving_fumbles']\n",
        "\n",
        "df['fumbles_lost'] = df['rushing_fumbles_lost'] + df['receiving_fumbles_lost']\n",
        "\n",
        "# Step 2: Group by season and player_name\n",
        "season_on_season_df = df.groupby(['season', 'player_name'])\n",
        "\n",
        "# Step 3: Aggregations\n",
        "aggregations = {\n",
        "    'completions': ['sum'],\n",
        "    'passing_attempts': ['sum'],\n",
        "    'passing_yards': ['sum'],\n",
        "    'passing_tds': ['sum'],\n",
        "    'interceptions': ['sum'],\n",
        "    'passing_air_yards': ['sum'],\n",
        "    'passing_yards_after_catch': ['sum'],\n",
        "    'passing_first_downs': ['sum'],\n",
        "    'passing_2pt_conversions': ['sum'],\n",
        "    'rushing_carries': ['sum'],\n",
        "    'rushing_yards': ['sum'],\n",
        "    'rushing_tds': ['sum'],\n",
        "    'rushing_fumbles': ['sum'],\n",
        "    'rushing_fumbles_lost': ['sum'],\n",
        "    'rushing_first_downs': ['sum'],\n",
        "    'rushing_2pt_conversions': ['sum'],\n",
        "    'receptions': ['sum'],\n",
        "    'targets': ['sum'],\n",
        "    'receiving_yards': ['sum'],\n",
        "    'receiving_tds': ['sum'],\n",
        "    'receiving_fumbles': ['sum'],\n",
        "    'receiving_fumbles_lost': ['sum'],\n",
        "    'receiving_air_yards': ['sum'],\n",
        "    'receiving_yards_after_catch': ['sum'],\n",
        "    'receiving_first_downs': ['sum'],\n",
        "    'receiving_2pt_conversions': ['sum'],\n",
        "    'special_teams_tds': ['sum'],\n",
        "    'fantasy_points': ['sum'],\n",
        "    'fantasy_points_ppr': ['sum'],\n",
        "    'time_of_possession': ['sum'],\n",
        "    'team_passing_yards': ['sum'],\n",
        "    'team_rushing_yards': ['sum'],\n",
        "    'team_total_yards': ['sum'],\n",
        "    'team_passing_plays': ['sum'],\n",
        "    'team_rushing_plays': ['sum'],\n",
        "    'amount of points scored by the team': ['sum'],\n",
        "    'inj_probable_status': ['sum'],\n",
        "    'inj_questionable_status': ['sum'],\n",
        "    'inj_doubtful_status': ['sum'],\n",
        "    'inj_out_status': ['sum'],\n",
        "    'Offensive_Line_Pro_Bowl_Count': ['sum'],\n",
        "    'Offensive_Line_Past_Year_Sum': ['sum'],\n",
        "    'Offensive_Line_Past_3_Years_Sum': ['sum'],\n",
        "    'Offense_Pro_Bowl_Count': ['sum'],\n",
        "    'Offense_Past_Year_Sum': ['sum'],\n",
        "    'Offense_Past_3_Years_Sum': ['sum'],\n",
        "    'Defense_Pro_Bowl_Count': ['sum'],\n",
        "    'Defense_Past_Year_Sum': ['sum'],\n",
        "    'Defense_Past_3_Years_Sum': ['sum'],\n",
        "    'Defensive_Line_Pro_Bowl_Count': ['sum'],\n",
        "    'Defensive_Line_Past_Year_Sum': ['sum'],\n",
        "    'Defensive_Line_Past_3_Years_Sum': ['sum'],\n",
        "    'total_yards': ['sum'],\n",
        "    'age':'first',\n",
        "    'win':'sum',\n",
        "    'position': 'first',\n",
        "    'team': 'first',\n",
        "    'season': 'first',\n",
        "    'head_coach': 'first',\n",
        "    'years_exp': 'first',\n",
        "    'draft_number': 'first',\n",
        "    'in_pro_bowl': 'first',\n",
        "    'In_Pro_Bowl_Last_Year': 'first',\n",
        "    'Amount of Pro Bowls in Last 3 Years': 'sum',\n",
        "    'round': 'first',\n",
        "    'college': 'first',\n",
        "    'College Conference': 'first',\n",
        "    'playing':'sum',\n",
        "    'completions_over_7': 'sum',\n",
        "    'rushing_carries_over_20': 'sum',\n",
        "    'rushing_carries_70_percent': 'sum',\n",
        "    'rushing_yards_over_100': 'sum',\n",
        "    'total_yards_over_100': 'sum',\n",
        "    'rushing_tds_over_2': 'sum',\n",
        "    'receiving_tds_multiple': 'sum',\n",
        "    'receiving_yards_over_100': 'sum',\n",
        "    'fantasy_points_over_10': 'sum',\n",
        "    'roof_outdoors': 'sum',\n",
        "    'roof_dome': 'sum',\n",
        "    'roof_open': 'sum',\n",
        "    'roof_closed': 'sum',\n",
        "    'grass_field': 'sum',\n",
        "    'astroturf_field': 'sum',\n",
        "    'other_turf_field':'sum',\n",
        "    'fumbles': ['sum'],\n",
        "    'fumbles_lost': ['sum']\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "# Aggregate the dataframe\n",
        "agg_df = season_on_season_df.agg(aggregations)\n",
        "\n",
        "# Flatten MultiIndex columns\n",
        "agg_df.columns = ['_'.join(col).strip() for col in agg_df.columns.values]\n",
        "\n",
        "# Reset index to bring 'season' and 'player_name' back as regular columns\n",
        "agg_df = agg_df.reset_index()\n",
        "\n",
        "\n",
        "\n",
        "# Now agg_df is a DataFrame with 'season' and 'player_name' intact\n",
        "print(agg_df.columns)\n",
        "\n",
        "# Step 8: Categorize games based on start_time and game_weekday\n",
        "def categorize_game(row):\n",
        "    if row['game_weekday'] == 'Sunday':\n",
        "        if row['start_time'] < '17:00':\n",
        "            return 'Sunday Morning/Afternoon'\n",
        "        elif row['start_time'] < '21:00':\n",
        "            return 'Sunday Night'\n",
        "    elif row['game_weekday'] == 'Monday':\n",
        "        return 'Monday Night'\n",
        "    else:\n",
        "        return 'Saturday'\n",
        "\n",
        "df['game_category'] = df.apply(categorize_game, axis=1)\n",
        "\n",
        "game_category_counts = df.groupby(['player_name', 'season', 'game_category']).size().unstack(fill_value=0).reset_index()\n",
        "\n",
        "# Combine aggregated data with game category counts\n",
        "final_df = agg_df.reset_index().merge(game_category_counts, on=['player_name', 'season'], how='left')\n",
        "\n",
        "# Save or display final DataFrame\n",
        "print(final_df.info())\n",
        "\n",
        "# Define the output file path for the merged data\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\season_on_season_data.csv\"\n",
        "\n",
        "# Write the merged DataFrame to a CSV file\n",
        "final_df.to_csv(output_file_path, index=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bac41aae",
      "metadata": {
        "id": "bac41aae"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}