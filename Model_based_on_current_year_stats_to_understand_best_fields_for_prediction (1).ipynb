{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvd-RQ-dOnxm"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "I decided to do a model based on current data. This model is assuming you already know the variables for the season.\n",
        "Its assuming you know the yards, the tds, and all the necessary stats. Therefore, this mode comes out great. BUT,\n",
        "it does not accomplish my overall goal of trying to predict how well a running back will do because I already know the outcome.\n",
        "I used this just to see if any other fields are useful for the model.\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "# Specify the path to your CSV file\n",
        "csv_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\season_on_season_data.csv\"\n",
        "\n",
        "# Create the DataFrame\n",
        "final_df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Load the dataset\n",
        "data = final_df\n",
        "\n",
        "# Drop specified fields\n",
        "fields_to_drop = ['position_first',\n",
        "                  'fantasy_points_ppr_sum', 'season_first','player_name',\n",
        "                  'fantasy_points_over_10_sum','index'\n",
        "                 ]\n",
        "\n",
        "data = data.drop(columns=fields_to_drop)\n",
        "\n",
        "# Perform one-hot encoding for string variables\n",
        "encoded_data = pd.get_dummies(data)\n",
        "\n",
        "# Select features and target variable\n",
        "target = data['fantasy_points_sum']\n",
        "features = encoded_data.drop(columns=['fantasy_points_sum'])  # Exclude the target variable\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = features.corrwith(target)\n",
        "\n",
        "# Sort the correlations in descending order\n",
        "sorted_correlations = correlation_matrix.sort_values(ascending=False)\n",
        "\n",
        "# Print the top correlated features\n",
        "print(\"Top correlated features:\")\n",
        "print(sorted_correlations.head(50))  # Adjust the number to display more or fewer features\n",
        "\n",
        "'''\n",
        "What this tells me is SUMs carry more weight than Mean and Median because Mean and Median don't factor in injuries.\n",
        "With injuries, you have less points. Or even someone coming back from IR. Going to use Random Forest next to see what features\n",
        "are important. Therefore, when I do make it more predictive, I don't focus on injuries as much\n",
        "\n",
        "'''\n",
        "\n",
        "# Initialize Random Forest Regressor\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model to the data\n",
        "rf.fit(features, target)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = rf.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature importances\n",
        "feature_importance_df = pd.DataFrame({'Feature': features.columns, 'Importance': feature_importances})\n",
        "\n",
        "# Sort the DataFrame by importance\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print the top features\n",
        "print(\"Top features according to RandomForest:\")\n",
        "print(feature_importance_df.head(30))  # Adjust the number to display more or fewer features\n",
        "\n",
        "'''\n",
        "Random Forest shows me that yards are king.\n",
        "\n",
        "Now going to look at GBM to see how it looks\n",
        "'''\n",
        "# Initialize Gradient Boosting Regressor\n",
        "gbm = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model to the data\n",
        "gbm.fit(features, target)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = gbm.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature importances\n",
        "feature_importance_df = pd.DataFrame({'Feature': features.columns, 'Importance': feature_importances})\n",
        "\n",
        "# Sort the DataFrame by importance\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print the top features\n",
        "print(\"Top features:\")\n",
        "print(feature_importance_df.head(20))  # Adjust the number to display more or fewer features\n",
        "\n",
        "\n",
        "'''\n",
        "Interesting that time of possession differs a lot. This is also showing that yards are king while tds definitely matter as well\n",
        "Now lets try my linear regression model\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "# Select the features\n",
        "selected_features = ['total_yards_sum', 'rushing_tds_sum', 'receiving_tds_sum',\n",
        "                     'fumbles_lost_mean', 'Defensive_Line_Past_3_Years_Sum_sum',\n",
        "                     'time_of_possession_mean', 'amount of points scored by the team_mean',\n",
        "                     'targets_sum', 'team_total_yards_mean', 'Offense_Past_3_Years_Sum_sum',\n",
        "                     'rushing_carries_sum']\n",
        "\n",
        "# Select features and target variable\n",
        "X = data[selected_features]\n",
        "y = data['fantasy_points_sum']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Linear Regression model\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "# Fit the model to the training data\n",
        "linear_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = linear_reg.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "# Calculate R-squared\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared:\", r2)\n",
        "\n",
        "# Calculate Mean Absolute Error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "'''\n",
        "Now for the current year, this gives me an idea of my model working. But, I want to look in the past.\n",
        "So I am going to tweak my data a little to incorporate that. I am going to set this more up as a prediction where I don't use\n",
        "stats for the current season. The only stats I use for the current season are things I can learn at the beginning of the year\n",
        "such as weight, height, pro bowl information. I can't use the yards for the current year. I can use yards for previous years.\n",
        "Also, I cant use in game data. I have to use data from the past. So in the next part, that is what I am going to tweak. To set\n",
        "this up more for a prediction rather than the current.\n",
        "'''"
      ]
    }
  ]
}