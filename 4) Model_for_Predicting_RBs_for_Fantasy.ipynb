{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "2q-5j9xYSCYb",
        "outputId": "b19a69a0-dde1-4523-eff5-00319f8480ac"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\sulli\\\\OneDrive\\\\Documents\\\\last_season_all_team_and_player_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c592130c94b8>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Create the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mlast_season_all_team_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\sulli\\\\OneDrive\\\\Documents\\\\last_season_all_team_and_player_data.csv'"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Now here is where I am trying a Linear Regression Model because I want to be able to predict how many points a player will\n",
        "have in fantasy. And because I don't have a stagnant target, linear regression makes the most sense.\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from itertools import combinations\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Specify the path to your CSV file\n",
        "csv_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\last_season_all_team_and_player_data.csv\"\n",
        "\n",
        "# Create the DataFrame\n",
        "last_season_all_team_data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Load the dataset\n",
        "data = last_season_all_team_data\n",
        "\n",
        "# Drop specified fields\n",
        "fields_to_drop = ['player_id',\n",
        "                  'current_fantasy_points_ppr', 'season','player_name',\n",
        "                  'game_type','first_name','last_name',\n",
        "                  'entry_year','rookie_year'\n",
        "                 ]\n",
        "\n",
        "data = data.drop(columns=fields_to_drop)\n",
        "\n",
        "# Perform one-hot encoding for string variables\n",
        "encoded_data = pd.get_dummies(data)\n",
        "\n",
        "# Select features and target variable\n",
        "target = data['current_fantasy_points']\n",
        "features = encoded_data.drop(columns=['current_fantasy_points'])  # Exclude the target variable\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = features.corrwith(target)\n",
        "\n",
        "# Sort the correlations in descending order\n",
        "sorted_correlations = correlation_matrix.sort_values(ascending=False)\n",
        "\n",
        "# Initialize Random Forest Regressor\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model to the data\n",
        "rf.fit(features, target)\n",
        "\n",
        "# Get feature importances\n",
        "rf_feature_importances = rf.feature_importances_\n",
        "\n",
        "# Initialize Gradient Boosting Regressor\n",
        "gbm = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model to the data\n",
        "gbm.fit(features, target)\n",
        "\n",
        "# Get feature importances\n",
        "gbm_feature_importances = gbm.feature_importances_\n",
        "\n",
        "'''Select the features for linear regression. I selected these fields because they had information on the player stats,\n",
        "information about the player themselves, and information about the team they played against. There are a lot of fantasy_points\n",
        "related fields that show high importance but they overlap with each other, so I tried to only choose one.\n",
        "Also past 3 years showed more importance to last season information, which makes sense. The more data you have, the easier it can\n",
        "be to predict.  But, last_season_targets for whatever reason was higher than the one that was 3 years. So I used that instead.\n",
        "'''\n",
        "\n",
        "\n",
        "selected_features = [\n",
        "    'Total Pro bowls defenders faced in past 3 years',\n",
        "    'last_season_total_yards_mean',\n",
        "    'last_season_fantasy_points_mean',\n",
        "    'last_season_fantasy_points_sum',\n",
        "    'Total pro bowls offensive teammates past 3 years',\n",
        "    'last_season_rushing_yards_mean',\n",
        "    'last_2_seasons_fantasy_points_mean',\n",
        "    'last_2_seasons_fantasy_points_ppr_mean',\n",
        "    'last_3_seasons_fantasy_points_ppr_mean',\n",
        "    'last_season_fantasy_points_ppr_sum',\n",
        "    'last_2_seasons_total_yards_over_100_mean',\n",
        "    'last_3_seasons_total_yards_over_100_mean',\n",
        "    'Total Pro bowls defensive linemen faced in past 3 years',\n",
        "    'last_3_seasons_fantasy_points_mean',\n",
        "    'last_weeks_of_last_season_fantasy_points_ppr_sum',\n",
        "    'last_3_seasons_total_yards_mean',\n",
        "    'last_2_seasons_total_yards_mean',\n",
        "    'last_weeks_of_last_season_fantasy_points_sum',\n",
        "    'draft_number',\n",
        "    'last_weeks_of_last_season_total_yards_mean',\n",
        "    'Total Pro bowls defenders faced in past year',\n",
        "    'Amount of Pro Bowls in Last 3 Years',\n",
        "    'last_weeks_of_last_season_fantasy_points_median',\n",
        "    'Total Pro bowls offensive linemen teammates in past 3 years',\n",
        "    'round',\n",
        "    'weight',\n",
        "    'Avg Pro bowls defenders faced in past 3 years'\n",
        "]\n",
        "\n",
        "# Select features and target variable for linear regression\n",
        "X = data[selected_features]\n",
        "y = data['current_fantasy_points']\n",
        "\n",
        "# Initialize Linear Regression model\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "linear_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = linear_reg.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Create a DataFrame to store the results so I can see them.\n",
        "results_df = pd.DataFrame({\n",
        "    'Feature': features.columns,\n",
        "    'Correlation': correlation_matrix,\n",
        "    'RF Feature Importance': rf_feature_importances,\n",
        "    'GBM Feature Importance': gbm_feature_importances\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by RF Feature Importance in descending order\n",
        "results_df_sorted = results_df.sort_values(by='RF Feature Importance', ascending=False)\n",
        "\n",
        "# Display the combination of features with the highest R-squared\n",
        "print('Here are what features seem the most important ')\n",
        "print(results_df_sorted.head(10))\n",
        "\n",
        "\n",
        "# Generate feature combinations and evaluate them with different train-test splits. I wanted to fully understand the best parameters to use\n",
        "results = []\n",
        "\n",
        "# Loop through different test sizes\n",
        "for test_size in [0.2, 0.3, 0.4]:\n",
        "    # Loop through different random states\n",
        "    for random_state in [42, 10, 100]:\n",
        "        # Split the data into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "        # Loop through different feature combinations\n",
        "        for i in range(10, len(selected_features) + 1):\n",
        "            for combination in combinations(selected_features, i):\n",
        "                selected_features_comb = list(combination)\n",
        "\n",
        "                # Select features and target variable for linear regression\n",
        "                X_comb = data[selected_features_comb]\n",
        "\n",
        "                # Fit the model to the training data\n",
        "                linear_reg.fit(X_train, y_train)\n",
        "\n",
        "                # Make predictions on the testing data\n",
        "                y_pred_comb = linear_reg.predict(X_test)\n",
        "\n",
        "                # Calculate evaluation metrics\n",
        "                mse_comb = mean_squared_error(y_test, y_pred_comb)\n",
        "                r2_comb = r2_score(y_test, y_pred_comb)\n",
        "                mae_comb = mean_absolute_error(y_test, y_pred_comb)\n",
        "\n",
        "                results.append({\n",
        "                    'Test Size': test_size,\n",
        "                    'Random State': random_state,\n",
        "                    'Features': ', '.join(selected_features_comb),\n",
        "                    'MSE': mse_comb,\n",
        "                    'R-squared': r2_comb,\n",
        "                    'MAE': mae_comb\n",
        "                })\n",
        "                # Create a DataFrame from the results\n",
        "results_comb_df = pd.DataFrame(results)\n",
        "\n",
        "\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\feature_combinations_results.csv\"\n",
        "\n",
        "results_comb_df.to_csv(output_file_path, index=False)\n",
        "\n",
        "# Sort the results_comb_df DataFrame based on R-squared values in descending order\n",
        "sorted_results_df = results_comb_df.sort_values(by='R-squared', ascending=False)\n",
        "\n",
        "# Display the combination of features with the highest R-squared\n",
        "best_result = sorted_results_df.iloc[0]  # Get the row with the highest R-squared\n",
        "\n",
        "# Display the combination of features with the highest R-squared in a table. This tells me the ideal combination to use\n",
        "print(\"Best combination of features based on R-squared:\")\n",
        "print(tabulate([best_result], headers='keys', tablefmt='pretty'))\n",
        "\n",
        "# If you want to save this best result to a CSV file\n",
        "best_result.to_csv(r\"C:\\Users\\sulli\\OneDrive\\Documents\\best_feature_combination.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the features\n",
        "selected_features = ['Total Pro bowls defenders faced in past 3 years',\n",
        "                     'last_3_seasons_rushing_tds_sum',\n",
        "                     'Total pro bowls offensive teammates past 3 years',\n",
        "                     'last_3_seasons_rushing_yards_sum', 'draft_number',\n",
        "                     'Pro Bowl Count in Past 3 Years', 'last_season_targets_sum',\n",
        "                     'last_3_seasons_fantasy_points_mean', 'last_3_seasons_rushing_carries_sum',\n",
        "                     'Total pro bowls offensive line teammates past 3 years', 'years_exp'\n",
        "]\n",
        "\n",
        "# Select features and target variable\n",
        "X = data[selected_features]\n",
        "y = data['current_fantasy_points']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=100)\n",
        "\n",
        "# Initialize Linear Regression model\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "# Fit the model to the training data\n",
        "linear_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = linear_reg.predict(X_test)\n",
        "\n",
        "# Ensure that negative predictions are set to 0\n",
        "y_pred = [max(0, pred) for pred in y_pred]\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "# Calculate R-squared\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared:\", r2)\n",
        "\n",
        "# Calculate Mean Absolute Error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Filter the dataset to include only the 2023 season\n",
        "data_2023 = last_season_all_team_data[last_season_all_team_data['season'] == 2023]\n",
        "\n",
        "# Select only the desired data points\n",
        "selected_columns = selected_features + ['current_fantasy_points']\n",
        "\n",
        "data_2023_selected = data_2023[selected_columns]\n",
        "\n",
        "# Make predictions on the data_2023_selected dataset\n",
        "data_2023_selected['predicted_fantasy_points'] = linear_reg.predict(data_2023_selected[selected_features])\n",
        "\n",
        "# Ensure that negative predictions are set to 0\n",
        "data_2023_selected['predicted_fantasy_points'] = data_2023_selected['predicted_fantasy_points'].apply(lambda x: max(0, x))\n",
        "\n",
        "# Calculate the difference based on the specified condition\n",
        "data_2023_selected['difference'] = data_2023_selected.apply(\n",
        "    lambda row: abs(row['current_fantasy_points'] - row['predicted_fantasy_points']), axis=1)\n",
        "\n",
        "# Calculate the desired statistics\n",
        "num_rows = len(data_2023_selected)\n",
        "average_difference = data_2023_selected['difference'].mean()\n",
        "average_difference_per_game = average_difference / 17\n",
        "\n",
        "# Print the results in a table\n",
        "table_data = [\n",
        "    [\"Number of Running Backs\", num_rows],\n",
        "    [\"Average Difference\", average_difference],\n",
        "    [\"Average Difference per Game\", average_difference_per_game]\n",
        "]\n",
        "\n",
        "print(tabulate(table_data, headers=[\"Metric\", \"Value\"], tablefmt=\"pretty\"))\n",
        "\n",
        "# Save the results to a CSV file\n",
        "output_file_path = r\"C:\\Users\\sulli\\OneDrive\\Documents\\data_2023_selected.csv\"\n",
        "data_2023_selected.to_csv(output_file_path, index=False)\n",
        "\n",
        "'''\n",
        "So the average difference between predicted and actual is 22.94 but if you divide that by the amount of games per season, which\n",
        "is 17, you get 1.35. That means I am only off 1.35 per game which is something I am happy about because of how close it is.\n",
        "When Yahoo or ESPN predict how running backs will do, most of the time they are off by an average of about 2-5 per week. So\n",
        "the fact I am able to build something for running backs that could rival them is an achievement. This shows I can potentially\n",
        "use this for 2024 and be able to win fantasy or even better, take this to a business like DraftKings or FanDuel, or even ESPN,\n",
        "and be able to show them the model and show them it can work based on the data collected.  This also showed me that adding\n",
        "pro bowlers for defense turned out better than I imagined considering it was a top two feature. I thought it would be important\n",
        "but not this important. When I looked at the 2023 data more closely, I saw that for rookies, I was actually not far off as\n",
        "well, which was a worry point because they have really no past data to look at.  It shows being a high draft pick in the first\n",
        "round matters.\n",
        "\n",
        "In conclusion, this shows my model does have potential but there are some more specifics I would love to look at like how\n",
        "fast a RB is or how good of a QB they are working with is.  However, what I feel I've proven is that I made a model that\n",
        "can combat the likes of ESPN. For that, I am happy. The next step is figuring out how to project on a week to week basis how\n",
        "well someone will do.\n",
        "'''"
      ],
      "metadata": {
        "id": "IxKsXqY6UjUf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
